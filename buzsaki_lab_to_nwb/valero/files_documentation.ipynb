{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymatreader import read_mat\n",
    "import json \n",
    "\n",
    "project_root = Path(\"/home/heberto/buzaki\")\n",
    "session_path = project_root /  \"fCamk1_200827_sess9\"\n",
    "assert session_path.is_dir()\n",
    "\n",
    "session_files_path_list = list(session_path.iterdir())\n",
    "# Dump to a file in the same folder\n",
    "json_directory = Path.cwd() / \"_json_files\"\n",
    "json_directory.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# Adjust the figure size\n",
    "plt.figure(figsize=(16, 8))\n",
    "# Adjust all the fonts\n",
    "plt.rcParams.update({'font.size': 25})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_files_as_string(files):\n",
    "    # Add a tuple with size\n",
    "    files = [(file_path.name, f\"size: {file_path.stat().st_size / 1024**2 :,.2f} MiB\") for file_path in files]\n",
    "\n",
    "    # Sort the list by file size in descending order\n",
    "    files.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Determine the maximum width for alignment based on longest file name length\n",
    "    max_file_name_length = max(len(name) for name, _ in files)\n",
    "    max_size_width = max_file_name_length + len(\"  size: \")\n",
    "\n",
    "    # Create new list with formatted strings\n",
    "    file_as_string = [f\"{name.ljust(max_file_name_length)} {size}\" for name, size in files]\n",
    "    \n",
    "    return file_as_string\n",
    "\n",
    "\n",
    "def build_keys_and_types(dictionary):\n",
    "    \"\"\"\n",
    "    Construct a new dictionary that contains type and optionally value or shape information \n",
    "    for each value in the input dictionary. This function handles nested dictionaries and treats \n",
    "    numpy arrays and lists in a specific way.\n",
    "\n",
    "    The function creates a new key-value pair for every key-value pair in the input dictionary. \n",
    "    The value is another dictionary that always contains the 'type' key and might contain the 'value', \n",
    "    'shape' or 'length' key depending on the original value's type and size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "        The input dictionary to be analyzed. It may contain nested dictionaries, numpy arrays,\n",
    "        lists, or other types of values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_dict : dict\n",
    "        The output dictionary that provides detailed information about each value in the original dictionary.\n",
    "        The value corresponding to each key is another dictionary that contains the following key-value pairs:\n",
    "        - 'type': A string describing the type of the original value.\n",
    "        - 'value': A string representing the original value. This key is present if the original value \n",
    "        is not a numpy array or list, or if it's a small numpy array or list (i.e., with fewer than 10 elements).\n",
    "        - 'shape': A string representing the shape of the original numpy array. This key is present if the \n",
    "        original value is a numpy array with 10 or more elements.\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, dict):\n",
    "            output_dict[key] = build_keys_and_types(value)\n",
    "        else:\n",
    "            output_dict[key] = extract_value_info(value)\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def extract_value_info(value):\n",
    "    \"\"\"\n",
    "    Generate a dictionary that contains type and optionally value or shape information about the input value.\n",
    "\n",
    "    This function always adds the 'type' key to the output dictionary. Depending on the input value's type and size,\n",
    "    it might also add the 'value', 'shape', or 'length' key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : object\n",
    "        The input value. It can be of any type, including numpy array and list.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    value_info : dict\n",
    "        The output dictionary that contains the following key-value pairs:\n",
    "        - 'type': A string describing the input value's type.\n",
    "        - 'value': A string representing the input value. This key is present if the input value is not a numpy \n",
    "        array or list, or if it's a small numpy array or list (i.e., with fewer than 10 elements).\n",
    "        - 'shape': A string representing the shape of the input value if it's a numpy array with 10 or more elements.\n",
    "    \"\"\"\n",
    "    value_info = {\"type\": str(type(value))}\n",
    "    \n",
    "    if isinstance(value, (np.ndarray, list)):\n",
    "        length = len(value) if isinstance(value, list) else value.size\n",
    "        value_info[\"shape\"] = str(value.shape) if isinstance(value, np.ndarray) else str(length)\n",
    "        no_list_or_array_inside = not any(isinstance(item, (np.ndarray, list)) for item in value)\n",
    "        if length < 10 and no_list_or_array_inside:\n",
    "            value_info[\"value\"] = str(value)\n",
    "    else:\n",
    "        value_info[\"value\"] = str(value)\n",
    "\n",
    "    return value_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve file paths and sizes\n",
    "\n",
    "condition = lambda file_path: \".mat\" in file_path.name\n",
    "files = [file_path for file_path in session_files_path_list if condition(file_path)]\n",
    "\n",
    "files_as_string = format_files_as_string(files)\n",
    "files_as_string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = lambda file_path : \".mat\" not in file_path.name and file_path.is_file()\n",
    "files = [file_path for file_path in session_files_path_list if condition(file_path)]\n",
    "\n",
    "files_as_string = format_files_as_string(files)\n",
    "files_as_string\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the output:\n",
    "\n",
    "* `analogin.dat`, `8,203.18 MiB` : Probably raw data\n",
    "* `fCamk1_200827_sess9.dat`, `32,812.73 MiB` : TODO\n",
    "* `auxiliary.dat`, `3,076.19 MiB` : TODO\n",
    "* `time.dat`, `2,050.80 MiB` :  TODO\n",
    "* `TrialMapsAndRasters.pptx`, `1.02 MiB` : Collection of rasters, I don't think it matters. \n",
    "* `fCamk1_200827_sess9.lfp`, `1,367.20 MiB` :  LFP\n",
    "* `digitalin.dat`, `1,025.40 MiB` :  TODO\n",
    "* `supply.dat`, `1,025.40 MiB` :  TODO\n",
    "* `pulTime.npy`, `0.32 MiB` : TODO\n",
    "* `fCamk1_200827_sess9_HSE.HSE.evt`, `0.28 MiB` : TODO \n",
    "* `deepSuperficial_classification_fromRipples.png`, `0.14 MiB` : Figure, probably does not matter \n",
    "* `bz_DetectSWR.log`, `0.05 MiB` :  TODO\n",
    "* `bz_DetectSWR_manu.log`, `0.05 MiB` : TODO\n",
    "* `fCamk1_200827_sess9.xml`, `0.04 MiB` : TODO\n",
    "* `fCamk1_200827_sess9.nrs`, `0.00 MiB` : TODO\n",
    "* `4nA pulses.txt`, `0.00 MiB` : TODO\n",
    "* `info.rhd`, `0.00 MiB` : TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folders / Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = lambda file_path : \".mat\" not in file_path.name and file_path.is_file()\n",
    "files = [file_path for file_path in session_files_path_list if condition(file_path)]\n",
    "\n",
    "files_as_string = format_files_as_string(files)\n",
    "files_as_string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `session.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.session.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = mat_file[\"session\"]\n",
    "session_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data[\"general\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgeries_data = session_data[\"animal\"][\"surgeries\"]\n",
    "weight = surgeries_data[\"weight\"]\n",
    "f\"{weight / 1000:2.3f} kg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sessionInfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.sessionInfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.EventExplorer.SessionMetadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.EventExplorer.SessionMetadata.mat\"\n",
    "\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is empty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Behavior.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.Behavior.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `behavior.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.behavior.cellinfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this is the file with the most information. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Tracking.Behavior.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.Tracking.Behavior.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"tracking\"][\"position\"][\"x\"][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subfolder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Tracking.Behavior.mat` subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / f\"{sub_folder.stem}.Tracking.Behavior.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \"_sub_folder\" + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"tracking\"][\"position\"][\"x\"][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this in the file above have the same position data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Linearized.Behavior.mat` subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / f\"{sub_folder.stem}.Linearized.Behavior.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \"_sub_folder\" + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"position\"][\"x\"][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it is the same position again here. \n",
    "\n",
    "However, this has the trials as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"trials\"][\"startPoint\"][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems the position and not the times as we need. Let's look for other folder to see if we can find the trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera matlab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / \"Basler_acA1280-60gc__21606137__20200827_110730202.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"camera\" + \"_sub_folder\" + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here they just copied the camera frame by frame (!)\n",
    "\n",
    "```\n",
    "\n",
    "{\n",
    "  \"frames\": {\n",
    "    \"r\": {\n",
    "      \"type\": \"<class 'numpy.ndarray'>\",\n",
    "      \"shape\": \"(1024, 204, 53143)\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "How long is the video 53_143 / 30 = 1_771.43 seconds -> 29.52 minutes\n",
    "\n",
    "Taking the sampling_rate of 30 Hz, we can see that the video is 1_771.43 seconds long and the ntransform to minutes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual maze mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / \"virtualMaze.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = f\"{file_path.stem}\" + \"_sub_folder\" + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems just like a map of the maze\n",
    "\n",
    "```\n",
    "  \"maze\": {\n",
    "    \"type\": \"<class 'numpy.ndarray'>\",\n",
    "    \"value\": \"[[ 11.09870461 109.25348571]\\n [ 12.12486221   0.85756268]]\"\n",
    "  }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roi tracking .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / \"roiTracking.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = f\"{file_path.stem}\" + \"_sub_folder\" + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this is a just a map with the reigon where they are doing the tracking of the position with the camera:\n",
    "\n",
    "```\n",
    "  \"roiTracking\": {\n",
    "    \"type\": \"<class 'numpy.ndarray'>\",\n",
    "    \"value\": \"[[  31.25 1015.  ]\\n [ 185.75 1019.5 ]\\n [ 184.25    5.5 ]\\n [  17.75    2.5 ]\\n [  31.25 1015.  ]]\"\n",
    "  }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplifier digital events `.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / \"amplifier.DigitalIn.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = f\"{file_path.stem}\" + \"_sub_folder\" + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"][\"ints\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"][\"ints\"][0]  # I think those ar the intervals of the pulses in the local time for the behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"][\"dur\"][1]  # I don't think they are ordered though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pulse duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"][\"intsPeriods\"]  # Note sure what it is this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TTL / Synch\n",
    "\n",
    "```\n",
    "dict_keys(['timestampsOn', 'timestampsOff', 'ints', 'dur', 'intsPeriods'])\n",
    "```\n",
    "I think this is the TTLs that synchronize the events. Come to this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"][\"timestampsOff\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"][\"timestampsOff\"][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"digitalIn\"][\"dur\"][0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analog signals in sub-folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following\n",
    "* `auxiliary.dat`\n",
    "* `supply.dat`\n",
    "* `time.dat`\n",
    "* `digitalin.dat`\n",
    "\n",
    "But two xml files:\n",
    "* `fCamk1_200827_sess9.xml` which I guess it the main recorder\n",
    "* `amplifier.xml` which I don't know what it does.\n",
    "\n",
    "The first is on the top directory, the other one is here.\n",
    "\n",
    "Note that in the sub-folder we only have `amplifier.xml` are they different?\n",
    "\n",
    "Let's test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_path =  session_path /  \"fCamk1_200827_sess9.xml\"\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "tree = ElementTree.parse(xml_file_path)\n",
    "root = tree.getroot()\n",
    "acq = root.find('acquisitionSystem')\n",
    "nbits = int(acq.find('nBits').text)\n",
    "num_channels = int(acq.find('nChannels').text)\n",
    "sampling_rate = float(acq.find('samplingRate').text)\n",
    "voltage_range = float(acq.find('voltageRange').text)\n",
    "# offset = int(acq.find('offset').text)\n",
    "amplification = float(acq.find('amplification').text)\n",
    "\n",
    "print(f\"{num_channels=}, {sampling_rate=}, {voltage_range=}, {amplification=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "\n",
    "xml_file_path =  sub_folder /  \"amplifier.xml\"\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "tree = ElementTree.parse(xml_file_path)\n",
    "root = tree.getroot()\n",
    "acq = root.find('acquisitionSystem')\n",
    "nbits = int(acq.find('nBits').text)\n",
    "num_channels = int(acq.find('nChannels').text)\n",
    "sampling_rate = float(acq.find('samplingRate').text)\n",
    "voltage_range = float(acq.find('voltageRange').text)\n",
    "# offset = int(acq.find('offset').text)\n",
    "amplification = float(acq.find('amplification').text)\n",
    "\n",
    "print(f\"{num_channels=}, {sampling_rate=}, {voltage_range=}, {amplification=}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "The top level:\n",
    "```\n",
    "num_channels=32, sampling_rate=30000.0, voltage_range=20.0, amplification=1000.0\n",
    "```\n",
    "\n",
    "The amplifier:\n",
    "```\n",
    "num_channels=32, sampling_rate=30000.0, voltage_range=20.0, amplification=1000.0\n",
    "```\n",
    "\n",
    "They seem similar. I wonder what we have two but we have a lot of redundancy in the conversion data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_names = [\"digitalin.dat\", \"time.dat\", \"supply.dat\", \"auxiliary.dat\"]\n",
    "\n",
    "\n",
    "from spikeinterface.extractors.neoextractors import NeuroScopeRecordingExtractor\n",
    "\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "\n",
    "for name in signal_names:\n",
    "    file_path = sub_folder / f\"{name}\" \n",
    "    assert file_path.is_file(), file_path\n",
    "\n",
    "    sig_dtype = 'int16' if nbits <= 16 else 'int32'\n",
    "    data = np.memmap(file_path, dtype=sig_dtype, mode='r', offset=0).reshape(-1, num_channels)\n",
    "    time = data.shape[0] / sampling_rate\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    print(\"---------------\")\n",
    "    print(f\"{file_path.name=} \\n\")\n",
    "    print(f\"num_samples: {num_samples:,}, time: {time:.2f} seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "```\n",
    "---------------\n",
    "file_path.name='digitalin.dat' \n",
    "\n",
    "num_samples: 1,684,470, time: 56.15 seconds\n",
    "---------------\n",
    "file_path.name='time.dat' \n",
    "\n",
    "num_samples: 3,368,940, time: 112.30 seconds\n",
    "---------------\n",
    "file_path.name='supply.dat' \n",
    "\n",
    "num_samples: 1,684,470, time: 56.15 seconds\n",
    "---------------\n",
    "file_path.name='auxiliary.dat' \n",
    "\n",
    "num_samples: 5,053,410, time: 168.45 seconds\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ripples.events.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.ripples.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_intervals = ripples_data[\"timestamps\"]\n",
    "peaks = ripples_data[\"peaks\"]\n",
    "peak_normed_power = ripples_data[\"peakNormedPower\"]\n",
    "\n",
    "ripple_stats_data = ripples_data[\"rippleStats\"][\"data\"]\n",
    "peak_frequency = ripple_stats_data[\"peakFrequency\"]\n",
    "peak_duration = ripple_stats_data[\"duration\"]\n",
    "peak_amplitude = ripple_stats_data[\"peakAmplitude\"]\n",
    "\n",
    "peaks.shape, peak_normed_power.shape, peak_frequency.shape, peak_duration.shape, peak_amplitude.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract indexed data\n",
    "ripple_stats_maps = ripples_data[\"rippleStats\"][\"maps\"]\n",
    "\n",
    "ripple_raw = ripple_stats_maps[\"ripples_raw\"]\n",
    "ripple_frequency = ripple_stats_maps[\"frequency\"]\n",
    "ripple_phase = ripple_stats_maps[\"phase\"]\n",
    "ripple_amplitude = ripple_stats_maps[\"amplitude\"]\n",
    "ripple_raw.shape, ripple_frequency.shape, ripple_phase.shape, ripple_amplitude.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / \"chanMap.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"chanMap\"+ \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected = mat_file[\"connected\"]  \n",
    "connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"chanMap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"chanMap0ind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"kcoords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {2: \"red\", 1: \"blue\", 3: \"green\", 4: \"yellow\"}\n",
    "channel_to_shank =  mat_file[\"kcoords\"]\n",
    "colors_for_k_cores = [colors[int(k)] for k in channel_to_shank]\n",
    "channel_index = mat_file[\"chanMap\"]\n",
    "channel_index = mat_file[\"chanMap0ind\"]\n",
    "\n",
    "x_coords = mat_file[\"xcoords\"][:]\n",
    "y_coords = mat_file[\"ycoords\"][:]\n",
    "\n",
    "plt.scatter(x_coords, y_coords, color=colors_for_k_cores)\n",
    "\n",
    "for i in range(x_coords.size):\n",
    "    channel_text = f\"idx={channel_index[i]} - grp={channel_to_shank[i]}\"\n",
    "    plt.text(x_coords[i], y_coords[i], channel_text, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.datainterfaces import NeuroScopeRecordingInterface\n",
    "\n",
    "session_id = session_path.stem\n",
    "\n",
    "# Add Recording\n",
    "file_path = session_path / f\"{session_id}.dat\"\n",
    "assert file_path.is_file()\n",
    "xml_file_path = session_path / f\"{session_id}.xml\"\n",
    "\n",
    "interface = NeuroScopeRecordingInterface(file_path=str(file_path), xml_file_path=str(xml_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.recording_extractor.get_channel_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.recording_extractor.get_property(\"group_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.recording_extractor.get_property(\"channel_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = interface.recording_extractor.get_channel_ids()\n",
    "\n",
    "small_trace = interface.recording_extractor.get_traces(start_frame=0, end_frame=1000, channel_ids=channel_ids)\n",
    "small_trace_no_channels = interface.recording_extractor.get_traces(start_frame=0, end_frame=1000)\n",
    "\n",
    "# Small test to see if traces are layed out as I expect\n",
    "np.testing.assert_allclose(small_trace, small_trace_no_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {2: \"red\", 1: \"blue\", 3: \"green\", 4: \"yellow\"}\n",
    "channel_to_shank =  mat_file[\"kcoords\"]\n",
    "colors_for_k_cores = [colors[int(k)] for k in channel_to_shank]\n",
    "channel_index = mat_file[\"chanMap\"]\n",
    "channel_index = mat_file[\"chanMap0ind\"]\n",
    "channel_name = interface.recording_extractor.get_property(\"channel_name\")\n",
    "\n",
    "\n",
    "x_coords = mat_file[\"xcoords\"][:]\n",
    "y_coords = mat_file[\"ycoords\"][:]\n",
    "\n",
    "plt.scatter(x_coords, y_coords, color=colors_for_k_cores)\n",
    "\n",
    "for i in range(x_coords.size):\n",
    "    channel_text = f\"idx={channel_index[i]} - grp={channel_to_shank[i]}\"\n",
    "    x = mat_file[\"xcoords\"][i]\n",
    "    y = mat_file[\"ycoords\"][i]\n",
    "    plt.text(x, y, channel_text, size=10)\n",
    "    name = channel_name[i]\n",
    "    plt.text(x, y - 5, name, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_extractor = interface.recording_extractor\n",
    "recording_to_matlab_data_map = []\n",
    "channel_ids_in_matlab = mat_file[\"chanMap0ind\"]\n",
    "\n",
    "\n",
    "channel_ids_in_matlab_str = [str(channel_ids_in_matlab[i]) for i in channel_ids_in_matlab]\n",
    "locations = np.array([mat_file[\"xcoords\"], mat_file[\"ycoords\"]]).T\n",
    "recording_extractor.set_channel_locations(channel_ids=channel_ids_in_matlab_str, locations=locations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_extractor.set_property(key=\"brain_area\", values=[\"CA1\"] * recording_extractor.get_num_channels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_extractor.get_property(\"brain_area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_extractor.get_property_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_extractor.get_property(\"group_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = recording_extractor.get_property(\"group_name\")\n",
    "group_to_color_map = {\"Group2\": \"red\", \"Group1\": \"blue\", \"Group3\": \"green\", \"Group4\": \"yellow\"}\n",
    "colors_for_groups = [group_to_color_map[name] for name in group_name]\n",
    "\n",
    "location = recording_extractor.get_property(\"location\")\n",
    "x_coords, y_coords = location[:, 0], location[:, 1]\n",
    "\n",
    "# plt.scatter(x, y)\n",
    "plt.scatter(x_coords, y_coords, color=colors_for_groups)\n",
    "\n",
    "channel_name = recording_extractor.get_property(\"channel_name\")\n",
    "for i in range(x_coords.size):\n",
    "    x = x_coords[i]\n",
    "    y = y_coords[i]\n",
    "    channel_text = channel_name[i]\n",
    "    plt.text(x, y, channel_text, size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_extractor.get_channel_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_path = Path.home() / \"conversion_nwb\"\n",
    "\n",
    "stub_path_list = list((output_dir_path / \"nwb_stub\").iterdir())\n",
    "\n",
    "file_path = stub_path_list[0]\n",
    "\n",
    "import pynwb \n",
    "\n",
    "# Open file with pynwb\n",
    "io = pynwb.NWBHDF5IO(str(file_path), mode='r', load_namespaces=True)\n",
    "nwbfile = io.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = nwbfile.electrodes.to_dataframe()\n",
    "x_coords, y_coords, group_name = data_frame.rel_x, data_frame.rel_y, data_frame.group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_to_color_map = {\"Group2\": \"red\", \"Group1\": \"blue\", \"Group3\": \"green\", \"Group4\": \"yellow\"}\n",
    "colors_for_groups = [group_to_color_map[name] for name in group_name]\n",
    "\n",
    "location = recording_extractor.get_property(\"location\")\n",
    "\n",
    "# plt.scatter(x, y)\n",
    "plt.scatter(x_coords, y_coords, color=colors_for_groups)\n",
    "\n",
    "channel_name = recording_extractor.get_property(\"channel_name\")\n",
    "for i in range(x_coords.size):\n",
    "    x = x_coords[i]\n",
    "    y = y_coords[i]\n",
    "    channel_text = channel_name[i]\n",
    "    plt.text(x, y, channel_text, size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chanCoords.channelInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = session_path / f\"{session_path.stem}.chanCoords.channelInfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"chanCoords\"+ \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.brainRegions.channelInfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"brainRegions.channelInfo\"+ \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = lambda file_path : \"LED\" in file_path.name\n",
    "led_files = [file_path for file_path in session_files_path_list if condition(file_path)] \n",
    "\n",
    "files_as_string = format_files_as_string(led_files)\n",
    "files_as_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in led_files:\n",
    "    if \"uLEDResponse_raster\" in file_path.name:\n",
    "        continue\n",
    "    print(file_path.name)\n",
    "    assert file_path.is_file(), file_path\n",
    "\n",
    "    mat_file = read_mat(file_path) \n",
    "\n",
    "    result = build_keys_and_types(mat_file)\n",
    "    json_output = json.dumps(result, indent=2)\n",
    "\n",
    "    json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "    with open(json_directory / json_name, 'w') as f:\n",
    "        f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optogenetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = lambda file_path : \"optogenetic\" in file_path.name\n",
    "files = [file_path for file_path in session_files_path_list if condition(file_path)] \n",
    "\n",
    "files_as_string = format_files_as_string(files)\n",
    "files_as_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.optogeneticPulses.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.optogeneticResponse.cellinfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "import h5py \n",
    "\n",
    "file_path = h5py.File(file_path, 'r')\n",
    "# mat_file = read_mat(file_path) \n",
    "file_path[\"optogeneticResponses\"].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path[\"optogeneticResponses\"][\"stimulationEpochs\"][:][:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = lambda file_path : \"eeg\" in file_path.name\n",
    "files = [file_path for file_path in session_files_path_list if condition(file_path)] \n",
    "\n",
    "files_as_string = format_files_as_string(files)\n",
    "files_as_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.eegstates.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SleepState.states`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.SleepState.states.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMG\n",
    "It seems there is only one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.EMGFromLFP.LFP.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theta (`thetaEpochs.states`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.thetaEpochs.states.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "mat_file = read_mat(file_path)\n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulses (`pulses.events.mat`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.pulses.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"pulses\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"pulses\"][\"eventGroupID\"][:][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"pulses\"][\"analogChannel\"][:][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heberto/miniconda3/envs/neuroconv_env/lib/python3.10/site-packages/pymatreader/utils.py:230: UserWarning: Complex objects (like classes) are not supported. They are imported on a best effort base but your mileage will vary.\n",
      "  warn('Complex objects (like classes) are not supported. '\n"
     ]
    }
   ],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.HSE.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['HSE'], dtype='<U3'), array([1], dtype=uint8), 3952, 3952)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hse_data = mat_file[\"HSE\"]\n",
    "start_time, stop_time = hse_data[\"timestamps\"][:, 0], hse_data[\"timestamps\"][:, 1] \n",
    "peaks = hse_data[\"peaks\"]\n",
    "event_id_labels = hse_data[\"eventIDlabels\"]\n",
    "event_id = hse_data[\"eventID\"]\n",
    "center = hse_data[\"center\"]\n",
    "\n",
    "np.unique(event_id_labels), np.unique(event_id), np.unique(peaks).size, np.unique(center).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.81  ,  12.365 ,  12.789 ,  14.8345,  15.9645,  21.346 ,\n",
       "        28.087 ,  35.8615,  37.531 ,  39.9335,  43.3225,  45.118 ,\n",
       "        45.3245,  47.5805,  48.3395,  58.8215,  59.101 ,  66.89  ,\n",
       "        81.6045,  84.6415,  99.5275, 103.814 , 112.7415, 116.454 ,\n",
       "       117.4325])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.716,  12.354,  12.791,  14.878,  15.987,  21.357,  28.092,\n",
       "        35.875,  37.499,  40.02 ,  43.311,  45.064,  45.353,  47.574,\n",
       "        48.391,  58.83 ,  59.104,  66.911,  81.608,  84.518,  99.583,\n",
       "       103.83 , 112.749, 116.465, 117.459])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaks[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.679, 12.277, 12.739, 14.751, 15.903]),\n",
       " array([ 6.941, 12.453, 12.839, 14.918, 16.026]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time[:5], stop_time[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDE states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.UDStates.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_and_down_states_data = mat_file[\"UDStates\"]\n",
    "\n",
    "intervals = up_and_down_states_data[\"ints\"]\n",
    "up_intervals = intervals[\"UP\"]\n",
    "up_start_time, up_stop_time = up_intervals[:, 0], up_intervals[:, 1]\n",
    "down_intervals = intervals[\"DOWN\"]\n",
    "down_start_time, down_stop_time = down_intervals[:, 0], down_intervals[:, 1]\n",
    "\n",
    "up_start_time.shape, down_start_time.shape, up_stop_time.shape, down_stop_time.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and sort UP and DOWN intervals\n",
    "combined_start_times = np.concatenate((up_start_time, down_start_time))\n",
    "combined_stop_times = np.concatenate((up_stop_time, down_stop_time))\n",
    "combined_states = np.array(['UP'] * len(up_start_time) + ['DOWN'] * len(down_start_time))\n",
    "\n",
    "# Create an array of indices that sorts the start times\n",
    "sort_indices = np.argsort(combined_start_times)\n",
    "\n",
    "# Sort all arrays using the sorting indices\n",
    "combined_start_times = combined_start_times[sort_indices]\n",
    "combined_stop_times = combined_stop_times[sort_indices]\n",
    "combined_states = combined_states[sort_indices]\n",
    "\n",
    "# Create TimeIntervals\n",
    "states_intervals = TimeIntervals(name='states_intervals')\n",
    "\n",
    "# Add a new column for states\n",
    "states_intervals.add_column(name='state', description='State (UP or DOWN)', data=combined_states)\n",
    "\n",
    "# Add intervals\n",
    "for start, stop, state in zip(combined_start_times, combined_stop_times, combined_states):\n",
    "    states_intervals.add_interval(start, stop, state=state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.ACGPeak.cellinfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spikes cell info (`spikes.cellinfo.mat`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.spikes.cellinfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.spikes.cellinfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_data = mat_file[\"spikes\"]\n",
    "spikes_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spikes_data[\"times\"]), type(spikes_data[\"ts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_data[\"ts\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(10):\n",
    "    plt.scatter(spikes_data[\"times\"][index], (index + 1 ) * np.ones(spikes_data[\"times\"][index].size), s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(min(spike_train), max(spike_train)) for spike_train in spikes_data[\"times\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ws_temp.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"ws_temp.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"ws_temp\" + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analog signals in top folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw signal and LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.dat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "from spikeinterface.extractors.neoextractors import NeuroScopeRecordingExtractor\n",
    "\n",
    "recording = NeuroScopeRecordingExtractor(file_path=file_path)\n",
    "recording"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "```\n",
    "NeuroScopeRecordingExtractor: 32 channels - 30.0kHz - 1 segments - 537,603,840 samples \n",
    "                              17,920.13s (4.98 hours) - int16 dtype - 32.04 GiB\n",
    "  file_path: /home/heberto/buzaki/fCamk1_200827_sess9/fCamk1_200827_sess9.dat\n",
    "```\n",
    "We see this is around 5 hours of recording. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.lfp\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "from spikeinterface.extractors.neoextractors import NeuroScopeRecordingExtractor\n",
    "\n",
    "recording = NeuroScopeRecordingExtractor(file_path=file_path)\n",
    "recording"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the sampling rate is wrong. Let's test with the current value from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 1.25 * 10**3 # 1.25 kHz\n",
    "duration_seconds = recording.get_num_frames() / sampling_rate\n",
    "duration_minutes = duration_seconds / 60.0\n",
    "duration_hours = duration_minutes / 60.0\n",
    "duration_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is five hours. This should be corrected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other signals in top folder\n",
    "We have the following\n",
    "* `analogin.dat`\n",
    "* `auxiliary.dat`\n",
    "* `supply.dat`\n",
    "* `time.dat`\n",
    "* `digitalin.dat`\n",
    "\n",
    "\n",
    "Let's check the XML first from where their metadata comes from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_path =  session_path /  \"fCamk1_200827_sess9.xml\"\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "tree = ElementTree.parse(xml_file_path)\n",
    "root = tree.getroot()\n",
    "acq = root.find('acquisitionSystem')\n",
    "nbits = int(acq.find('nBits').text)\n",
    "num_channels = int(acq.find('nChannels').text)\n",
    "sampling_rate = float(acq.find('samplingRate').text)\n",
    "voltage_range = float(acq.find('voltageRange').text)\n",
    "# offset = int(acq.find('offset').text)\n",
    "amplification = float(acq.find('amplification').text)\n",
    "\n",
    "print(f\"{num_channels=}, {sampling_rate=}, {voltage_range=}, {amplification=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_names = [\"digitalin.dat\", \"time.dat\", \"supply.dat\", \"auxiliary.dat\", \"analogin.dat\"]\n",
    "\n",
    "\n",
    "for name in signal_names:\n",
    "    file_path = session_path / f\"{name}\" \n",
    "    assert file_path.is_file(), file_path\n",
    "\n",
    "    sig_dtype = 'int16' if nbits <= 16 else 'int32'\n",
    "    data = np.memmap(file_path, dtype=sig_dtype, mode='r', offset=0).reshape(-1,    )\n",
    "    time = data.shape[0] / sampling_rate\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    print(\"---------------\")\n",
    "    print(f\"{file_path.name=} \\n\")\n",
    "    print(f\"num_samples: {num_samples:,}, time: {time / 60.0:.2f} minutes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "They seem too short:\n",
    "```\n",
    "---------------\n",
    "file_path.name='digitalin.dat' \n",
    "\n",
    "num_samples: 16,800,120, time: 9.33 minutes\n",
    "---------------\n",
    "file_path.name='time.dat' \n",
    "\n",
    "num_samples: 33,600,240, time: 18.67 minutes\n",
    "---------------\n",
    "file_path.name='supply.dat' \n",
    "\n",
    "num_samples: 16,800,120, time: 9.33 minutes\n",
    "---------------\n",
    "file_path.name='auxiliary.dat' \n",
    "\n",
    "num_samples: 50,400,360, time: 28.00 minutes\n",
    "---------------\n",
    "file_path.name='analogin.dat' \n",
    "\n",
    "num_samples: 134,400,960, time: 74.67 minutes\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera / Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / \"Basler_acA1280-60gc__21606137__20200827_110730202.avi\"\n",
    "assert file_path.is_file(), file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "file_path = sub_folder / \"Basler_acA1280-60gc__21606137__20200827_110730202.avi\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "# Use Pyav to get the video metadata\n",
    "import av\n",
    "container = av.open(str(file_path))\n",
    "\n",
    "video = container.streams.video[0]\n",
    "\n",
    "print(\"width\", video.codec_context.width)\n",
    "print(\"height\", video.codec_context.height)\n",
    "print(\"pixel format\", video.codec_context.pix_fmt)\n",
    "print(\"frame rate\", video.codec_context.framerate)\n",
    "print(\"bit rate\", video.codec_context.bit_rate)\n",
    "print(\"codec\", video.codec_context.codec_tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.start_time, video.average_rate, video.duration, video.time_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.datainterfaces.behavior.video.video_utils import get_video_timestamps\n",
    "\n",
    "timestamps_cv = get_video_timestamps(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.datainterfaces.behavior.sleap.sleap_utils import extract_timestamps\n",
    "\n",
    "\n",
    "timestamps_sleap = np.array(extract_timestamps(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_cv.shape, timestamps_sleap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_cv[0], timestamps_sleap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestmaps_cv_shifted = timestamps_cv + 0.0333333333333333\n",
    "np.isclose(timestmaps_cv_shifted, timestamps_sleap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(timestmaps_cv_shifted, timestamps_sleap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "container = av.open(str(file_path))\n",
    "stream = container.streams.video[0]\n",
    "\n",
    "counter = 0\n",
    "for frame in container.decode(stream):\n",
    "    time_base = frame.time_base\n",
    "    dts_time = float(frame.dts * time_base)\n",
    "    pts_time = float(frame.pts * time_base)\n",
    "    time = float(frame.time)\n",
    "    print(f\"{dts_time= }, {pts_time=}, {time=}\")\n",
    "    counter += 1\n",
    "    \n",
    "    if counter > 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for packet in container.demux(stream):\n",
    "    print(f\"{counter=}\")\n",
    "    print('Packet PTS:', packet.pts)\n",
    "    print('Packet DTS:', packet.dts)\n",
    "    print('Packet Duration:', packet.duration)\n",
    "    print('Packet Timebase:', packet.time_base)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "# Open the video file\n",
    "container = av.open(str(file_path))\n",
    "stream = container.streams.video[0]\n",
    "\n",
    "# Iterate over the first 10 packets in the video stream\n",
    "for i, packet in enumerate(container.demux(stream)):\n",
    "    print(f'Packet #{i + 1}:')\n",
    "    print('PTS:', packet.pts)\n",
    "    print('DTS:', packet.dts)\n",
    "    print('Duration:', packet.duration)\n",
    "    print('Timebase:', packet.time_base)\n",
    "    print('\\n')  # Print a newline for readability\n",
    "    \n",
    "    # Stop after 10 packets\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_path_here = project_root /  \"fCamk1_200827_sess9\"\n",
    "session_path_here = project_root / \"fCamk2\" / \"fCamk2_201012_sess1\"\n",
    "session_path_here = project_root / \"fCamk3_201030_sess12\"\n",
    "file_path = session_path_here / f\"{session_path_here.stem}.session.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "epoch_list = mat_file[\"session\"][\"epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/heberto/buzaki/fCamk3_201030_sess12')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_path_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fCamk3_201030_094008': {'file_path': PosixPath('/home/heberto/buzaki/fCamk3_201030_sess12/fCamk3_201030_094008/Basler_acA1280-60gc__21606137__20201030_094038065.avi'),\n",
       "  'start_time': 5940.64},\n",
       " 'fCamk3_201030_135409': {'file_path': PosixPath('/home/heberto/buzaki/fCamk3_201030_sess12/fCamk3_201030_135409/Basler_acA1280-60gc__21606137__20201030_135451101.avi'),\n",
       "  'start_time': 20515.872}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_path = session_path_here\n",
    "name_of_folders = [session_path / f\"{epoch['name']}\" for epoch in epoch_list]\n",
    "start_times = [epoch['startTime'] for epoch in epoch_list]\n",
    "assert all([folder.is_dir() for folder in name_of_folders])\n",
    "\n",
    "# For each of the folder in name_of_folders look for the .avi file and \n",
    "# This can't be done with a rglob because some sessions like `fCamk3_201030_sess12` contain sub-nested sessions.\n",
    "epoch_to_video_info = {}\n",
    "for folder, start_time in zip(name_of_folders, start_times):\n",
    "    video_file_paths = list(folder.glob(\"*.avi\"))\n",
    "    assert len(video_file_paths) <= 1, \"There should be only one .avi file in each epoch folder\"\n",
    "    if len(video_file_paths) == 1:\n",
    "        epoch_to_video_info[folder.name] = dict(file_path=video_file_paths[0], start_time=start_time)\n",
    "        \n",
    "epoch_to_video_info\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-03-15'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_file[\"session\"][\"general\"][\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.291324435185185"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "epoch_df = pd.DataFrame(epoch_list)\n",
    "epoch_df.stopTime.max() / (3600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints out five hours as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                 |   startTime |   stopTime |   duration_seconds |   duration_hours |\n",
      "|:---------------------|------------:|-----------:|-------------------:|-----------------:|\n",
      "| fCamk2_201012_090020 |        0    |    3794.69 |           3794.69  |         1.05408  |\n",
      "| fCamk2_201012_115808 |     3794.69 |    6988.77 |           3194.08  |         0.887244 |\n",
      "| fCamk2_201012_130347 |     6988.77 |    9449.44 |           2460.67  |         0.68352  |\n",
      "| fCamk2_201012_134511 |     9449.44 |   10273.7  |            824.224 |         0.228951 |\n",
      "| fCamk2_201012_140000 |    10273.7  |   11848.8  |           1575.1   |         0.437529 |\n"
     ]
    }
   ],
   "source": [
    "epoch_df[\"duration_seconds\"] = (epoch_df.stopTime - epoch_df.startTime)\n",
    "epoch_df[\"duration_hours\"] = epoch_df.duration_seconds / (3600)\n",
    "print(epoch_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_df[\"duration_hours\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| name                 |   startTime |   stopTime | behavioralParadigm   | environment   | manipulation     |   duration_hours |\n",
    "|:---------------------|------------:|-----------:|:---------------------|:--------------|:-----------------|-----------------:|\n",
    "| fCamk1_200827_084028 |        0    |    5194.88 | BaselinePre          | Home cage     | None             |         1.44302  |\n",
    "| fCamk1_200827_101538 |     5194.88 |    8284.64 | PreStim              | Home cage     | uLED random stim |         0.858267 |\n",
    "| fCamk1_200827_110712 |     8284.64 |   10081.4  | Maze                 | Linear maze   | uLED random stim |         0.499102 |\n",
    "| fCamk1_200827_113839 |    10081.4  |   11803.6  | PostStim             | Home cage     | uLED random stim |         0.478382 |\n",
    "| fCamk1_200827_125535 |    11803.6  |   17920.1  | BaselinePost         | Home cage     | None             |         1.69904  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,796.77 seconds  \n",
    "How does it relate to 53143 samples which is the samples for the timestamps in the trials table for the different behavioral files in the .mat files\n",
    "\n",
    "53143 samples / 1796.77 seconds = 29.6 samples per second (Hz)\n",
    "\n",
    "This is approximately 30 Hz whic fits wit the sampling rate of the camera.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `beahvior.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.behavior.cellinfo.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "\n",
    "trial_data = mat_file[\"behavior\"][\"trials\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The startTime is are the trial intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_intervals = trial_data[\"startPoint\"]\n",
    "start_time, stop_time = trial_intervals[:, 0], trial_intervals[:, 1]\n",
    "start_time.shape, stop_time.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visited arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visted_arm = trial_data[\"visitedArm\"]\n",
    "visted_arm.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recordings\n",
    "Seems to have only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"trials\"][\"recordings\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mat_file[\"behavior\"][\"trials\"][\"recordings\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mat_file[\"behavior\"][\"maps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"maps\"][0].shape, mat_file[\"behavior\"][\"maps\"][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"maps\"][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"noStimulatedMaps\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"noStimulatedMaps\"][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"stimulatedMaps\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"noStimulatedMapsLegend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"stimulatedMapsLegend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = mat_file[\"behavior\"][\"timestamps\"]\n",
    "timestamps[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems taht the timestamps are already synchronized. That is, they start at their epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_timestamps = mat_file[\"behavior\"][\"masks\"][\"trials\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(trials_timestamps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be a map from timestamps [the index here] to trial. Let's confirm that using a figure. The trials with nan should represent the baseline. Let's change them by -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set np.nan to -1 in trial_timestamps\n",
    "trials_to_plot = trials_timestamps.copy()\n",
    "trials_to_plot[np.isnan(trials_to_plot)] = -20\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trials_to_plot)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am wrong. I think there is sjust some delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the indexes where the trials change\n",
    "trial_change_idx = np.nonzero(np.diff(trials_to_plot) != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_change_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timestamps[trial_change_idx]\n",
    "start_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the trials cover all the behavioral epoch.\n",
    "However, we also know that there is no stimulation on all of those trials. I wonder where I can get the times for the behavioral epoch of which there should be 5. Baseline - stim 1 - baseline - stim 2 - baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_intervals = mat_file[\"behavior\"][\"trials\"][\"startPoint\"]\n",
    "start_time, stop_time = trial_intervals[:, 0], trial_intervals[:, 1]\n",
    "\n",
    "# Calculate distance between stop_time and next start_time\n",
    "\n",
    "inter_trial_distance = start_time[1:] - stop_time[:-1]\n",
    "\n",
    "inter_trial_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = np.concatenate(mat_file[\"behavior\"][\"maps\"], axis=0)\n",
    "trial_mask = mat_file[\"behavior\"][\"masks\"][\"trials\"]\n",
    "maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mask = mat_file[\"behavior\"][\"masks\"][\"trials\"]\n",
    "trial_index = 1\n",
    "mask = trial_mask == trial_index\n",
    "position = mat_file[\"behavior\"][\"position\"]\n",
    "x, y = position[\"x\"], position[\"y\"]\n",
    "x_trial, y_trial = x[mask], y[mask]\n",
    "\n",
    "\n",
    "x_no_norm = x * maps[:, 0]\n",
    "y_no_norm = y * maps[:, 1]\n",
    "\n",
    "# Create a color gradient based on the index\n",
    "color_map = plt.cm.get_cmap('plasma')\n",
    "colors = np.linspace(0, 1, len(x_no_norm[mask]))\n",
    "\n",
    "# Plot with color gradient\n",
    "plt.scatter(x_no_norm[mask], y_no_norm[mask], c=colors, cmap=color_map)\n",
    "\n",
    "plt.colorbar()  # Add colorbar for reference\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Behavior.mat`\n",
    "This has the visited arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.Behavior.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file[\"behavior\"][\"maps\"][0].shape, mat_file[\"behavior\"][\"maps\"][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_direction = mat_file[\"behavior\"][\"masks\"][\"trialsDirection\"]\n",
    "trial_direction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = mat_file[\"behavior\"][\"trials\"]\n",
    "trial_intervals = trials[\"startPoint\"]\n",
    "visited_arm = trials[\"visitedArm\"]\n",
    "\n",
    "visited_arm[:5], visited_arm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform vistied_arm to 0 if value is 1 and to 1 otherwise\n",
    "visited_arm_complement = np.where(visited_arm == 1, 0, 1)\n",
    "\n",
    "np.where(visited_arm_complement != trial_direction)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_arm[110], trial_direction[110]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the plot below, it seems that this is the direction up and down no left and right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "\n",
    "trial_mask = mat_file[\"behavior\"][\"masks\"][\"trials\"]\n",
    "\n",
    "\n",
    "trials = [108, 109, 110]\n",
    "trials = [5, 6, 7, 8, 9]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(trials), figsize=(20, 4))  # Create subplots with 1 row and 5 columns\n",
    "\n",
    "for i, trial_index in enumerate(trials):\n",
    "    mask = trial_mask == trial_index\n",
    "    position = mat_file[\"behavior\"][\"position\"]\n",
    "    x, y = position[\"x\"], position[\"y\"]\n",
    "\n",
    "    # Create a color gradient based on the index\n",
    "    color_map = plt.cm.get_cmap('RdBu_r')\n",
    "    colors = np.linspace(0, 1, len(x[mask]))\n",
    "\n",
    "    # Plot with color gradient\n",
    "    scatter = axs[i].scatter(x[mask], y[mask], c=colors, cmap=color_map)\n",
    "\n",
    "    axs[i].set_title(f'Trial {trial_index}')  # Set title for each subplot\n",
    "    axs[i].set_xlabel('X')  # Set x-axis label for each subplot\n",
    "    axs[i].set_ylabel('Y')  # Set y-axis label for each subplot\n",
    "\n",
    "    # Add a small colorbar to each plot\n",
    "    divider = make_axes_locatable(axs[i])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(scatter, cax=cax)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "print(\"visited_arm\", visited_arm[trials])\n",
    "print(\"trial_direction\", trial_direction[trials])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see if the positions in different files have different units. \n",
    "\n",
    "Which are the files \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the top level of the session folder\n",
    "\n",
    "top_level_with_position = [\"behavior.cellinfo.mat\", \"Behavior.mat\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = top_level_with_position[1]\n",
    "for file_name in top_level_with_position:\n",
    "    file_path = session_path / f\"{session_path.stem}.{file_name}\"\n",
    "    assert file_path.is_file(), file_path\n",
    "\n",
    "    mat_file = read_mat(file_path) \n",
    "    position = mat_file[\"behavior\"][\"position\"]\n",
    "    x, y = position[\"x\"], position[\"y\"]\n",
    "\n",
    "    plt.plot(x, y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same position data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Linearized.Behavior.mat\"\n",
    "\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "\n",
    "file_path = sub_folder / f\"{sub_folder.stem}.{file_name}\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "position = mat_file[\"behavior\"][\"position\"]\n",
    "x, y = position[\"x\"], position[\"y\"]\n",
    "\n",
    "plt.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name  = \"Tracking.Behavior.mat\"\n",
    "\n",
    "sub_folder = session_path / f\"{session_path.stem.rsplit('_', 1)[0]}_110712\"\n",
    "assert sub_folder.is_dir()\n",
    "\n",
    "file_path = sub_folder / f\"{sub_folder.stem}.{file_name}\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "\n",
    "position = mat_file[\"tracking\"][\"position\"]\n",
    "x, y = position[\"x\"], position[\"y\"]\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.pulses.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "pulses = mat_file[\"pulses\"]\n",
    "pulses.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses[\"timestamps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = pulses[\"timestamps\"][:, 1] - pulses[\"timestamps\"][:, 0]\n",
    "duration[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses[\"analogChannel\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses[\"analogChannel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses[\"analogChannelsList\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses[\"intsPeriods\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.session.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "brain_regions_to_channels = read_mat(file_path)[\"session\"][\"brainRegions\"]\n",
    "\n",
    "# Invert the dictionary brain_regions_to_channels\n",
    "channel_to_brain_region_dict = {}\n",
    "for region, value in brain_regions_to_channels.items():\n",
    "    channels = value[\"channels\"]\n",
    "    channel_to_brain_region_dict |= {channel: region for channel in channels}\n",
    "    \n",
    "\n",
    "brain_region = [channel_to_brain_region_dict[i] for i in pulses[\"analogChannel\"]]\n",
    "brain_region[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses[\"eventGroupID\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_times = pulses[\"timestamps\"][1:] - pulses[\"timestamps\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses[\"duration\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses[\"eventGroupID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses[\"analogChannel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pulses[\"amplitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses[\"timestamps\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = pulses[\"intsPeriods\"]\n",
    "first_pulse = periods[0][0]\n",
    "last_pulse = periods[-1][1]\n",
    "\n",
    "first_pulse, last_pulse, (last_pulse - first_pulse) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_durations = periods[:, 1] - periods[:, 0] \n",
    "plt.hist(pulse_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = periods[:, 0]\n",
    "y = np.ones_like(x)\n",
    "width = periods[:, 1] - periods[:, 0]\n",
    "plt.bar(x=x, height=y, width=width, bottom=0, align='edge')\n",
    "\n",
    "# Let's plot the epochs as well\n",
    "\n",
    "file_path = session_path / f\"{session_path.stem}.session.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file_epochs = read_mat(file_path)\n",
    "epoch_list = mat_file_epochs[\"session\"][\"epochs\"]\n",
    "\n",
    "start_time_list = [epoch[\"startTime\"] for epoch in epoch_list[1:-1]]\n",
    "epoch_name = [epoch[\"behavioralParadigm\"] for epoch in epoch_list[1:-1]]\n",
    "\n",
    "# Add an annotation for every epoch in start_time_list\n",
    "for start_time in start_time_list:\n",
    "    plt.axvline(start_time, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=5)\n",
    "    \n",
    "# Add the name in the top for each epoch in epoch_name\n",
    "for start_time, name in zip(start_time_list, epoch_name):\n",
    "    plt.text(start_time, 1.1, name, rotation=45, horizontalalignment=\"center\")\n",
    "    \n",
    "plt.xlabel(\"Seconds\")\n",
    "\n",
    "# Remote frame in the y axis\n",
    "plt.yticks([])\n",
    "\n",
    "# Remote the frame\n",
    "plt.box(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juding by the time and duration the pulses cover the three epochs. The Prestim, the Maze and the PostStim.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses[\"analogChannel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses[\"eventGroupID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses[\"analogChannelsList\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = pulses[\"analogChannel\"]\n",
    "channel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_duration_ms = pulses[\"duration\"] * 1000\n",
    "plt.hist(pulse_duration_ms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is correct duration of 20 milliseconds as stated in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pulses[\"analogChannel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pulses[\"analogChannelsList\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optogenic pulses\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'fCamk1_200827_sess9.optogeneticResponse.cellinfo.mat size: 375.40 MiB',\n",
    " 'fCamk1_200827_sess9.optogeneticPulses.events.mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.optogeneticPulses.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "json_name = \"\".join(file_path.suffixes)[1:] + \".json\"\n",
    "with open(json_directory / json_name, 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_stimulation = mat_file[\"optoPulses\"][\"stimulationEpochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_length = epochs_stimulation[:, 1] - epochs_stimulation[:, 0]\n",
    "epochs_stimulation[epoch_length < 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them have negative length. I am confused about what this means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar for the periods[:, 0]\n",
    "\n",
    "# Adjust the figure size\n",
    "plt.figure(figsize=(16, 8))\n",
    "# Adjust all the fonts\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "x = epochs_stimulation[:, 0]\n",
    "y = np.ones_like(x)\n",
    "width = epochs_stimulation[:, 1] - epochs_stimulation[:, 0]\n",
    "plt.bar(x=x, height=y, bottom=0, align='edge')\n",
    "\n",
    "# Let's plot the epochs as well\n",
    "\n",
    "file_path = session_path / f\"{session_path.stem}.session.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file_epochs = read_mat(file_path)\n",
    "epoch_list = mat_file_epochs[\"session\"][\"epochs\"]\n",
    "\n",
    "start_time_list = [epoch[\"startTime\"] for epoch in epoch_list[1:-1]]\n",
    "epoch_name = [epoch[\"behavioralParadigm\"] for epoch in epoch_list[1:-1]]\n",
    "\n",
    "# Add an annotation for every epoch in start_time_list\n",
    "for start_time in start_time_list:\n",
    "    plt.axvline(start_time, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=5)\n",
    "    \n",
    "# Add the name in the top for each epoch in epoch_name\n",
    "for start_time, name in zip(start_time_list, epoch_name):\n",
    "    plt.text(start_time, 1.1, name, rotation=45, horizontalalignment=\"center\")\n",
    "    \n",
    "plt.xlabel(\"Seconds\")\n",
    "\n",
    "# Remote frame in the y axis\n",
    "plt.yticks([])\n",
    "\n",
    "# Remote the frame\n",
    "plt.box(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.SleepState.states.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_states_data = mat_file[\"SleepState\"]\n",
    "sleep_states_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = sleep_states_data[\"ints\"]\n",
    "available_states = [str(key) for key in intervals.keys()]\n",
    "available_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals[\"WAKEstate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals[\"REMstate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = sleep_states_data[\"idx\"]\n",
    "statenames = idx[\"statenames\"]\n",
    "statenames, len(statenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(idx[\"states\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are just the timestamps and the indexes corresponding to the statenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_states = [state for state in statenames if len(state) > 0]\n",
    "available_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[\"theta_states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(idx[\"theta_states\"][\"states\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 0 probabl ymeans the absence of signal but then there is theta vs non-theta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.thetaEpochs.states.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "mat_file = read_mat(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session general information (`sesion.mat`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.session.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "mat_file = read_mat(file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add epochs to nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = mat_file[\"session\"][\"epochs\"]\n",
    "epoch_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb.testing.mock.file import mock_NWBFile\n",
    "\n",
    "nwb_file = mock_NWBFile()\n",
    "\n",
    "nwb_file.add_epoch_column(name=\"behavioral_paradigm\", description=\"The behavioral paradigm of the epoch\")\n",
    "nwb_file.add_epoch_column(name=\"environment\", description=\"The environment in the epoch\")\n",
    "nwb_file.add_epoch_column(name=\"manipulation\", description=\"The stimulus in the epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epoch_list:\n",
    "    start_time = float(epoch[\"startTime\"])\n",
    "    stop_time = float(epoch[\"stopTime\"])\n",
    "    behavioral_paradigm = epoch[\"behavioralParadigm\"]\n",
    "    environment = epoch[\"environment\"]\n",
    "    manipulation = epoch[\"manipulation\"]\n",
    "    \n",
    "    nwb_file.add_epoch(start_time=start_time, stop_time=stop_time, behavioral_paradigm=behavioral_paradigm, environment=environment, manipulation=manipulation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwb_file.epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_available = list(session_path.rglob('*.avi'))\n",
    "assert len(videos_available) == 1, f\"There should be one and only one video file {videos_avaialble}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.datainterfaces import VideoInterface\n",
    "\n",
    "interface = VideoInterface(file_paths=videos_available)\n",
    "interface.get_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewards as events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.Behavior.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path) \n",
    "\n",
    "events_data = mat_file[\"behavior\"][\"events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timestamps and create labels for rewards\n",
    "reward_r_timestamps = events_data[\"rReward\"]\n",
    "reward_l_timestamps = events_data[\"lReward\"]\n",
    "label_reward_r = np.ones(reward_r_timestamps.shape[0], dtype=int)\n",
    "label_reward_l = np.zeros(reward_l_timestamps.shape[0], dtype=int)\n",
    "\n",
    "# Create a structure to concatenate timestamps and sort by them\n",
    "reward_r = np.vstack((reward_r_timestamps, label_reward_r))\n",
    "reward_l = np.vstack((reward_l_timestamps, label_reward_l))\n",
    "rewards = np.concatenate((reward_r, reward_l), axis=1)\n",
    "\n",
    "timestamps_both_rewards = rewards[0, :]\n",
    "rewards = rewards[:, timestamps_both_rewards.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = rewards[0, :]\n",
    "assert np.all(np.diff(timestamps) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(rewards.shape[1]), rewards[0, :])\n",
    "# Add an identity line in the plot\n",
    "np.diff(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ndx_events import LabeledEvents\n",
    "\n",
    "timestamps = rewards[0, :]\n",
    "data = rewards[1, :]\n",
    "\n",
    "events = LabeledEvents(\n",
    "    name='rewards',\n",
    "    description='rewards in the linear track',\n",
    "    timestamps=timestamps,\n",
    "    data=data,\n",
    "    labels=['right_reward', 'left_reward']\n",
    ")\n",
    "\n",
    "from pynwb.testing.mock.file import mock_NWBFile\n",
    "\n",
    "nwbfile = mock_NWBFile()\n",
    "\n",
    "\n",
    "nwbfile.add_acquisition(events)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add pulses "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.pulses.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "pulses_data = mat_file[\"pulses\"]\n",
    "pulses_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_intervals = pulses_data[\"timestamps\"] \n",
    "pulse_micro_led = pulses_data[\"analogChannel\"]\n",
    "pulse_amplitude = pulses_data[\"amplitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_amplitude[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses_data[\"analogChannel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pulses_data[\"eventGroupID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb.testing.mock.file import mock_NWBFile\n",
    "from pynwb.ogen import OptogeneticStimulusSite\n",
    "from pynwb.ogen import OptogeneticSeries\n",
    "\n",
    "nwbfile = mock_NWBFile()\n",
    "\n",
    "manufacturer = \"Neurolight Technologies\"\n",
    "name = \"N1-F21-O36 | 18\"\n",
    "description = (\"12 µLEDs, 10 x 15 µm each, 3 per shank\\n\"\n",
    "              \"Emission Peak λ = 460 nm and FWHM = 40 nm\\n\"\n",
    "              \"Typical irradiance of 33 mW/mm² (@ max operating current of 100 µA)\\n\"\n",
    "              \"32 recording channels, 8 per shank\\n\"\n",
    "              \"Electrode impedance of 1000 - 1500 kΩ at 1 kHz\\n\")\n",
    "            \n",
    "device_metadata = dict(name=name, description=description, manufacturer=manufacturer)\n",
    "if device_metadata[\"name\"] not in nwbfile.devices:\n",
    "    neurolight_probe = nwbfile.create_device(**device_metadata)\n",
    "    \n",
    "micro_led_ids = np.unique(pulse_micro_led)\n",
    "site_description = \"microscopic LED 10 x 15 µm each, 3 per shank. Each μLED has an emission area of 150 μm2\"\n",
    "location = \"dorsal right hippocampus (antero-posterior 2.0 mm, mediolateral 1.5 mm, dorsoventral 0.6 mm)\"\n",
    "micro_led_ids_to_site = dict()\n",
    "\n",
    "for id in micro_led_ids:\n",
    "\n",
    "    ogen_stim_site = OptogeneticStimulusSite(\n",
    "        name=f\"Microled site in Neurolight probe with id {id}\",\n",
    "        device=neurolight_probe,\n",
    "        description=site_description,\n",
    "        excitation_lambda=460.0,  # nm\n",
    "        location=location, # TODO find the mapping for precise location per site if possible\n",
    "    )\n",
    "    micro_led_ids_to_site[id] = ogen_stim_site\n",
    "    nwbfile.add_ogen_site(ogen_stim_site)\n",
    "\n",
    "\n",
    "for id in micro_led_ids:\n",
    "    site_intervals = pulse_intervals[pulse_micro_led == id]\n",
    "    site_amplitudes = pulse_amplitude[pulse_micro_led == id]\n",
    "    pulse_start_time, pulse_stop_time = site_intervals[:, 0], site_intervals[:, 1]\n",
    "    amplitude_at_start = np.zeros_like(pulse_start_time)\n",
    "    amplitude_at_stop = site_amplitudes \n",
    "\n",
    "    raise_time = 0.001 # 1 ms\n",
    "    rise_to_max_time = pulse_start_time + raise_time\n",
    "    amplitude_at_max = site_amplitudes\n",
    "\n",
    "    # Assume from the trapezoidal profile that the decay time is the same as the rise time \n",
    "    decay_time = pulse_stop_time + raise_time \n",
    "    amplitude_after_decay = np.zeros_like(decay_time)\n",
    "\n",
    "    timestamps = np.vstack((pulse_start_time, rise_to_max_time, pulse_stop_time, decay_time))\n",
    "    data = np.vstack((amplitude_at_start, amplitude_at_max, amplitude_at_stop, amplitude_after_decay))\n",
    "\n",
    "    site_timestamps = timestamps.T.flatten()\n",
    "    site_data = data.T.flatten()\n",
    "\n",
    "    optogenetic_series_description = (\"μLEDs were controlled with current (2-4.5 μA generating 0.02-0.1μW of total light power;\"\n",
    "                \"ref (15)) provided by a 12-channel current generator (OSC1Lite, NeuroNex Michigan Hub)\"\n",
    "                \"driven by an Arduino, which delivered trapezoid (1ms rise time)\"\n",
    "                \"blue light (centered emission at 460 nm, emission surface area = 150 mm2) 20 ms pulses at\"\n",
    "                \"random sites with a randomly variable (40-60ms) offset\")\n",
    "    optogenetic_site = micro_led_ids_to_site[id]\n",
    "    optogenetic_series = OptogeneticSeries(\n",
    "        name=f\"Stimuli from microLED site {id}\",\n",
    "        timestamps = site_timestamps,\n",
    "        data=site_data,\n",
    "        site=optogenetic_site,\n",
    "        description=optogenetic_series_description,\n",
    "    )\n",
    "\n",
    "    nwbfile.add_stimulus(optogenetic_series)\n",
    "\n",
    "    n = 4\n",
    "    zero = np.min(pulse_intervals[:, 0])\n",
    "    plt.plot((site_timestamps[:n] - zero) * 1000.0, site_data[:n]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_timestamps[:n] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps[:5, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps.T.flatten()[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.pulses.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "pulses_data = mat_file[\"pulses\"]\n",
    "pulses_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_intervals = pulses_data[\"timestamps\"] \n",
    "electrode_channel = pulses_data[\"analogChannel\"]\n",
    "amplitude = pulses_data[\"amplitude\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb.testing.mock.file import mock_NWBFile\n",
    "\n",
    "nwbfile = mock_NWBFile()\n",
    "\n",
    "from pynwb.epoch import TimeIntervals\n",
    "\n",
    "laser_description = (\n",
    "\"\"\"\n",
    "μLEDs were controlled with current (2-4.5 μA generating 0.02-0.1μW of total light power;\n",
    "ref (15)) provided by a 12-channel current generator (OSC1Lite, NeuroNex Michigan Hub)\n",
    "driven by an Arduino (https://github.com/valegarman), which delivered trapezoid (1ms rise time)\n",
    "blue light (centered emission at 460 nm, emission surface area = 150 mm2) 20 ms pulses at\n",
    "random sites with a randomly variable (40-60ms) offset.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "stimuli_laser_pulses = TimeIntervals(\n",
    "    name=\"laser_pulses\",\n",
    "    description=\"intervals for each pulse stimuli for the uLED electrodes\",\n",
    ")\n",
    "\n",
    "stimuli_laser_pulses.add_column(name=\"electrode_channel\", description=\"The electrode channel for the pulse\")\n",
    "stimuli_laser_pulses.add_column(name=\"amplitude\", description=\"The amplitude of the pulse\")\n",
    "\n",
    "for interval, channel, amp in zip(pulse_intervals, electrode_channel, amplitude):\n",
    "    start_time, stop_time = interval\n",
    "    channel = channel\n",
    "    row_dict = {\"start_time\": start_time, \"stop_time\": stop_time, \"electrode_channel\": channel, \"amplitude\": amp}\n",
    "    stimuli_laser_pulses.add_row(**row_dict)\n",
    "    \n",
    "\n",
    "nwbfile.add_time_intervals(stimuli_laser_pulses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ripples as events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = session_path / f\"{session_path.stem}.ripples.events.mat\"\n",
    "assert file_path.is_file(), file_path\n",
    "\n",
    "mat_file = read_mat(file_path)\n",
    "ripples_data = mat_file[\"ripples\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_intervals = ripples_data[\"timestamps\"]\n",
    "\n",
    "peaks = ripples_data[\"peaks\"]\n",
    "peak_normed_power = ripples_data[\"peakNormedPower\"]\n",
    "\n",
    "ripple_stats_data = ripples_data[\"rippleStats\"][\"data\"]\n",
    "\n",
    "peak_frequencies = ripple_stats_data[\"peakFrequency\"]\n",
    "ripple_durations = ripple_stats_data[\"duration\"]\n",
    "peak_amplitudes = ripple_stats_data[\"peakAmplitude\"]\n",
    "\n",
    "descriptions = dict(\n",
    "    ripple_durations=\"Duration of the ripple event.\",\n",
    "    peaks=\"Peak of the ripple.\",\n",
    "    peak_normed_power=\"Normed power of the peak.\",\n",
    "    peak_frequencies=\"Peak frequency of the ripple.\",\n",
    "    peak_amplitudes=\"Peak amplitude of the ripple.\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb.testing.mock.file import mock_NWBFile\n",
    "from pynwb import NWBFile, H5DataIO\n",
    "from pynwb.epoch import TimeIntervals\n",
    "\n",
    "\n",
    "nwbfile = mock_NWBFile()\n",
    "name = \"ripples\"\n",
    "table = TimeIntervals(name=name, description=\"Ripples and their metrics\")\n",
    "\n",
    "\n",
    "for start_time, stop_time in ripple_intervals:\n",
    "    table.add_row(start_time=start_time, stop_time=stop_time)\n",
    "\n",
    "for column_name, column_data in zip(\n",
    "    list(descriptions), [ripple_durations, peaks, peak_normed_power, peak_frequencies, peak_amplitudes]\n",
    "):\n",
    "    table.add_column(\n",
    "        name=column_name,\n",
    "        description=descriptions[column_name],\n",
    "        data=H5DataIO(column_data, compression=\"gzip\"),\n",
    "    )\n",
    "\n",
    "# Extract indexed data\n",
    "\n",
    "ripple_stats_maps = ripples_data[\"rippleStats\"][\"maps\"]\n",
    "\n",
    "ripple_raw = ripple_stats_maps[\"ripples_raw\"]\n",
    "ripple_frequencies = ripple_stats_maps[\"frequency\"]\n",
    "ripple_phases = ripple_stats_maps[\"phase\"]\n",
    "ripple_amplitudes = ripple_stats_maps[\"amplitude\"]\n",
    "\n",
    "indexed_descriptions = dict(\n",
    "    ripple_raw=\"Extracted ripple data.\",\n",
    "    ripple_frequencies=\"Frequency of each point on the ripple.\",\n",
    "    ripple_phases=\"Phase of each point on the ripple.\",\n",
    "    ripple_amplitudes=\"Amplitude of each point on the ripple.\",\n",
    ")\n",
    "\n",
    "for column_name, column_data in zip(\n",
    "    list(indexed_descriptions), [ripple_raw, ripple_frequencies, ripple_phases, ripple_amplitudes]\n",
    "):\n",
    "    table.add_column(\n",
    "        name=column_name,\n",
    "        description=indexed_descriptions[column_name],\n",
    "        index=list(range(column_data.shape[0])),\n",
    "        data=H5DataIO(column_data, compression=\"gzip\"),\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_frequencies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sorting and sorting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.datainterfaces import CellExplorerSortingInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_path / f\"{session_path.stem}.spikes.cellinfo.mat\"\n",
    "\n",
    "cell_explorer_interface = CellExplorerSortingInterface(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_cell_explorer = cell_explorer_interface.sorting_extractor\n",
    "sorter_cell_explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sorter = sorter_cell_explorer\n",
    "\n",
    "spike_range = {}\n",
    "for unit_id in sorter.unit_ids:\n",
    "\n",
    "    spikes = sorter.get_unit_spike_train(unit_id=unit_id, return_times=True) / 3600\n",
    "    first_spike, last_spike = spikes[0], spikes[-1]\n",
    "    spike_range[unit_id] = dict(first_spike=first_spike, last_spike=last_spike)\n",
    "    \n",
    "pd.DataFrame(spike_range).max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.datainterfaces import KiloSortSortingInterface\n",
    "\n",
    "folder_path = session_path / \"Kilosort_2020-08-28_231022\"\n",
    "kilosort_interface = KiloSortSortingInterface(folder_path=folder_path)\n",
    "kilosort_sorter = kilosort_interface.sorting_extractor\n",
    "kilosort_sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sorter = kilosort_sorter\n",
    "\n",
    "spike_range = {}\n",
    "for unit_id in sorter.unit_ids:\n",
    "\n",
    "    spikes = sorter.get_unit_spike_train(unit_id=unit_id, return_times=True) / 3600\n",
    "    first_spike, last_spike = spikes[0], spikes[-1]\n",
    "    spike_range[unit_id] = dict(first_spike=first_spike, last_spike=last_spike)\n",
    "    \n",
    "pd.DataFrame(spike_range).max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = session_path / \"Kilosort_2020-08-28_231022\"\n",
    "neuroscope_interface = NeuroScopeSortingInterface(folder_path=folder_path)\n",
    "\n",
    "neuroscope_sorter = neuroscope_interface.sorting_extractor\n",
    "neuroscope_sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intan header"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://intantech.com/files/Intan_RHD2000_data_file_formats.pdf\n",
    "\n",
    "Python format:\n",
    "https://intantech.com/downloads.html?tabSelect=Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_intan = session_path / \"info.rhd\"\n",
    "file_path_intan.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def read_qstring(f):\n",
    "    length = struct.unpack('<I', f.read(4))[0]\n",
    "\n",
    "    if length == 0xFFFFFFFF:\n",
    "        return None\n",
    "\n",
    "    length = length // 2  # Convert length from bytes to 16-bit Unicode words\n",
    "    a = []\n",
    "    \n",
    "    for _ in range(length):\n",
    "        a.append(struct.unpack('<H', f.read(2))[0])\n",
    "\n",
    "    return ''.join(chr(c) for c in a)\n",
    "\n",
    "def read_channel(f):\n",
    "    native_name = read_qstring(f)\n",
    "    custom_name = read_qstring(f)\n",
    "    native_order = struct.unpack('<h', f.read(2))[0]\n",
    "    custom_order = struct.unpack('<h', f.read(2))[0]\n",
    "    signal_type = struct.unpack('<h', f.read(2))[0]\n",
    "    enabled = struct.unpack('<h', f.read(2))[0]\n",
    "    chip_channel = struct.unpack('<h', f.read(2))[0]\n",
    "    board_stream = struct.unpack('<h', f.read(2))[0]\n",
    "    spike_scope_voltage_trigger_mode = struct.unpack('<h', f.read(2))[0]\n",
    "    spike_scope_voltage_treshold = struct.unpack('<h', f.read(2))[0]\n",
    "    spike_scope_digital_trigger_channel = struct.unpack('<h', f.read(2))[0]\n",
    "    spike_scope_digital_edge_polarity = struct.unpack('<h', f.read(2))[0]\n",
    "    electrode_impedance_magnitude = struct.unpack('<f', f.read(4))[0]\n",
    "    electrode_impedance_phase = struct.unpack('<f', f.read(4))[0]\n",
    "    \n",
    "    return {\n",
    "        'native_name': native_name,\n",
    "        'custom_name': custom_name,\n",
    "        'native_order': native_order,\n",
    "        'custom_order': custom_order,\n",
    "        'signal_type': signal_type,\n",
    "        'enabled': enabled,\n",
    "        'chip_channel': chip_channel,\n",
    "        'board_stream': board_stream,\n",
    "        \"spike_scope_voltage_trigger_mode\": spike_scope_voltage_trigger_mode,\n",
    "        \"spike_scope_voltage_treshold\": spike_scope_voltage_treshold,\n",
    "        \"spike_scope_digital_trigger_channel\": spike_scope_digital_trigger_channel,\n",
    "        \"spike_scope_digital_edge_polarity\": spike_scope_digital_edge_polarity,\n",
    "        \"electrode_impedance_magnitude\": electrode_impedance_magnitude,\n",
    "        \"electrode_impedance_phase\": electrode_impedance_phase\n",
    "    }\n",
    "\n",
    "def read_signal_group(f):\n",
    "    name = read_qstring(f)\n",
    "    prefix = read_qstring(f)\n",
    "    enabled = struct.unpack('<h', f.read(2))[0]\n",
    "    num_channels = struct.unpack('<h', f.read(2))[0]\n",
    "    num_amp_channels = struct.unpack('<h', f.read(2))[0]\n",
    "\n",
    "    channels = []\n",
    "    for i in range(num_channels):\n",
    "        channel = read_channel(f)\n",
    "        channels.append(channel)\n",
    "\n",
    "    return {\n",
    "        'name': name,\n",
    "        'prefix': prefix,\n",
    "        'enabled': enabled,\n",
    "        'num_channels': num_channels,\n",
    "        'num_amp_channels': num_amp_channels,\n",
    "        'channels': channels\n",
    "    }\n",
    "\n",
    "with open(file_path_intan, 'rb') as f:\n",
    "    # Read magic number\n",
    "    magic_number = struct.unpack('<I', f.read(4))[0]\n",
    "    print(hex(magic_number))\n",
    "    print(\"0xC6912702\")\n",
    "    # Read version number\n",
    "    version = struct.unpack('<h', f.read(2))[0]\n",
    "    version_small = struct.unpack('<h', f.read(2))[0]\n",
    "    # Unpack a single float with struct.unpack\n",
    "    sampling_rate = struct.unpack('<f', f.read(4))[0]\n",
    "    dsp_enabled = struct.unpack('<h', f.read(2))[0]\n",
    "    dsp_cutoff_frequency = struct.unpack('<f', f.read(4))[0]\n",
    "    lower_bandwidth = struct.unpack('<f', f.read(4))[0]\n",
    "    uppper_bandwith = struct.unpack('<f', f.read(4))[0]\n",
    "    desired_dsp_cutoff_frequency = struct.unpack('<f', f.read(4))[0]\n",
    "    desired_lower_bandwidth = struct.unpack('<f', f.read(4))[0]\n",
    "    desired_upper_bandwidth = struct.unpack('<f', f.read(4))[0]\n",
    "    \n",
    "    print(f\"Version = {version}.{version_small}\")\n",
    "    print(f\"{sampling_rate=}, {dsp_enabled=}, {dsp_cutoff_frequency=}, {lower_bandwidth=}\")\n",
    "    print(f\"{desired_dsp_cutoff_frequency=}, {desired_lower_bandwidth=}, {desired_upper_bandwidth=}\")\n",
    "    \n",
    "    notch_filter_mode = struct.unpack('<h', f.read(2))[0]\n",
    "    desired_impedance_test_frequency = struct.unpack('<f', f.read(4))[0]\n",
    "    actual_impedance_test_frequency = struct.unpack('<f', f.read(4))[0]\n",
    "    \n",
    "    print(f\"{notch_filter_mode=}, {desired_impedance_test_frequency=}, {actual_impedance_test_frequency=}\")    \n",
    "    \n",
    "    # # Read note fields\n",
    "    \n",
    "    note1 = read_qstring(f)\n",
    "    note2 = read_qstring(f)\n",
    "    note3 = read_qstring(f)\n",
    "    \n",
    "    print(\"Notes\")\n",
    "    print(f\"{note1=}, {note2=}, {note3=}\")\n",
    "    \n",
    "    number_of_temperature_sensors = struct.unpack('<h', f.read(2))[0]\n",
    "    \n",
    "    if version >= 1 and version_small >= 1.3:\n",
    "        board_mode = struct.unpack('<h', f.read(2))[0]\n",
    "    else:\n",
    "        board_mode = \"Not supported in this version\"\n",
    "    if version >= 2:\n",
    "        reference_channel = struct.unpack('<h', f.read(2))[0]\n",
    "    else:\n",
    "        reference_channel = \"Not supported in this version\"\n",
    "    print(f\"{number_of_temperature_sensors=}, {board_mode=}, {reference_channel=}\")\n",
    "\n",
    "    number_of_signal_groups = struct.unpack('<h', f.read(2))[0]\n",
    "    print(\"Signal groups\", number_of_signal_groups)\n",
    "    \n",
    "    \n",
    "    # signal_group_name = read_qstring(f)\n",
    "    # signal_group_prefix = read_qstring(f)\n",
    "    # singal_group_enabled = struct.unpack('<h', f.read(2))[0]\n",
    "    # number_of_channels = struct.unpack('<h', f.read(2))[0]\n",
    "    # number_of_amplifier_channels = struct.unpack('<h', f.read(2))[0]\n",
    "    \n",
    "    # print(f\"{signal_group_name=}, {signal_group_prefix=}, {singal_group_enabled=}, {number_of_channels=}, {number_of_amplifier_channels=}\")\n",
    "    \n",
    "    # channels = read_channel(f)\n",
    "    # print(channels)\n",
    "    \n",
    "    signal_groups = []\n",
    "    for _ in range(number_of_signal_groups):\n",
    "        signal_group = read_signal_group(f)\n",
    "        signal_groups.append(signal_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signal_groups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for signal_group_index in range(number_of_signal_groups):\n",
    "    print(f\"port = {signal_groups[signal_group_index]['name']}\")\n",
    "    print(signal_groups[signal_group_index][\"num_channels\"])\n",
    "    print(signal_groups[signal_group_index][\"num_amp_channels\"])\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check NWB result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_dir_path = Path.home() / \"conversion_nwb\"\n",
    "\n",
    "stub_path_list = list((output_dir_path / \"nwb_stub\").iterdir())\n",
    "\n",
    "file_path = stub_path_list[0]\n",
    "\n",
    "import pynwb \n",
    "\n",
    "# Open file with pynwb\n",
    "io = pynwb.NWBHDF5IO(str(file_path), mode='r', load_namespaces=True)\n",
    "nwbfile = io.read()\n",
    "nwbfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = nwbfile.electrodes.to_dataframe()\n",
    "import pandas as pd\n",
    "# Show all the entries of the dataframe\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[dataframe.channel_name == \"ch9grp3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.acquisition['Video: Basler_acA1280-60gc__21606137__20200827_110730202']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_module = nwbfile.processing[\"ecephys\"][\"LFP\"]\n",
    "lfp_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_module[\"ElectricalSeriesLF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroconv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
