{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "\n",
    "# from mat73 import loadmat as loadmat_mat73\n",
    "# from mat4py import loadmat as loadmat_mat4py\n",
    "\n",
    "import h5py\n",
    "from scipy.io import loadmat as loadmat_scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session analysis\n",
    "Let's start with a session to look at the files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and their description. A first take"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peter Petersen, one of the members of the Buzsaki lab, has shared with us the following documents that contain the structure of the cell explorer format:\n",
    "\n",
    "* [new format](https://cellexplorer.org/data-structure/)\n",
    "* [old format](https://github.com/buzsakilab/buzcode/wiki/Data-Formatting-Standards)\n",
    "\n",
    "He referred to the old format as buzcode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.SleepState.states.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.ripples.events.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.cell_metrics.cellinfo.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/chanMap.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.spikes.cellinfo.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.Behavior.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.mono_res.cellinfo.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.session.mat')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_path = Path(\"/home/heberto/buzaki/e13_16f1_210302/\")\n",
    "session_files_path_list = list(session_path.iterdir())\n",
    "session_files_path_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as Cody mention, we have seen some experimental data from this lab already and we are familiar with the names.\n",
    "\n",
    "In a [previous conversion](https://github.com/catalystneuro/buzsaki-lab-to-nwb/blob/master/buzsaki_lab_to_nwb/yuta_visual_cortex/files_documentation.ipynb) I found out that the matlab files contain the following information:\n",
    "\n",
    "\n",
    "\n",
    "* `SleepState.states` : This can be considered processed data involving up-down intervals. This can be include as process data.\n",
    "* `chanMap` : This seems to be concerned with information of the channels in the electrode. For example we find both the x and y coordinates of each of the channels. The structure of the files here is (1, n_channels) where n_channels is 64 for this setup.\n",
    "* `session` : Contains behavioral info and general information related to the session such as the experimenter, the species, the strain and timestamps for the creation of the session.\n",
    "\n",
    "As you see, we have the following descriptions missing:\n",
    "* `.ripples.events.mat`: \n",
    "* `Behavior` : \n",
    "\n",
    "Which is something that we would do below.\n",
    "\n",
    "#### Spike sorting\n",
    "The files related to spike sorting were the following in a previous conversion.\n",
    "\n",
    "For the previous conversion those were the files related to **cell explorer format / interface**:\n",
    "* `metric_cell_info`\n",
    "* `mono_res_cellinfo`\n",
    "* `spikes.cell_info`\n",
    "\n",
    "They don't seem equivalent to the ones here. We need to confirm that they are equivalent to the following files in this conversion:\n",
    "* `cell_metrics.cellinfo.mat`\n",
    "* `cell_metrics.cellinfo`\n",
    "* `spikes.cellinfo`\n",
    "\n",
    "This is done below.\n",
    "\n",
    "Apparently, mono_res means Monosynaptic connections.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring some files\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SleepState.states`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see now which matlab file opener works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__header__ <class 'bytes'>\n",
      "__version__ <class 'str'>\n",
      "__globals__ <class 'list'>\n",
      "SleepState <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"e13_16f1_210302.SleepState.states.mat\"\n",
    "# Open file_path with loadmat_scipy from scipy\n",
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "# Iterate over the keys and print the type of the values\n",
    "for key in mat_file.keys():\n",
    "    print(key, type(mat_file[key]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a recursive structure. Let's print the keys, types and shapes (if numpy array) for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_keys_and_types(dictionary):\n",
    "    output_dict = {}\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, dict):\n",
    "            output_dict[key] = build_keys_and_types(value)\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            if value.size > 10:\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'shape': str(value.shape)\n",
    "                }\n",
    "            else:\n",
    "                # Print small arrays\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'value': str(value)\n",
    "                }\n",
    "        elif isinstance(value, list):\n",
    "            if len(value) > 10:\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'length': len(value)\n",
    "                }\n",
    "            else:\n",
    "                # Print small lists\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'value': str(value)\n",
    "                }\n",
    "        else:\n",
    "            output_dict[key] = {\n",
    "                \"type\": str(type(value)),\n",
    "                \"value\": str(value),\n",
    "            }\n",
    "    return output_dict\n",
    "\n",
    "# Define your sleep_state_dict here\n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "# Dump to a file in the same folder\n",
    "json_directory = Path.cwd() / \"_json_files\"\n",
    "json_directory.mkdir(exist_ok=True)\n",
    "with open(json_directory / 'sleep_state_dict.json', 'w') as f:\n",
    "    f.write(json_output)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a matlab licence, you can also just explore the file there. There are two things to look for, large arrays that might\n",
    "correspond to behavorial data and metadata from the experiment.\n",
    "\n",
    "Because I know the data from this lab I will be looking for the REM state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_state_dict = mat_file[\"SleepState\"]\n",
    "json_dict = json.dumps(build_keys_and_types(sleep_state_dict), indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WAKEstate': array([[    1,  1806],\n",
       "        [ 2947,  3015],\n",
       "        [ 3314,  3345],\n",
       "        [ 3995,  4025],\n",
       "        [ 4525,  5819],\n",
       "        [ 6221,  6272],\n",
       "        [ 6834,  6876],\n",
       "        [ 7481,  7508],\n",
       "        [ 7614,  7652],\n",
       "        [ 7879,  7897],\n",
       "        [ 8111, 14739],\n",
       "        [15887, 21006]], dtype=uint16),\n",
       " 'NREMstate': array([[ 1807,  2946],\n",
       "        [ 3016,  3241],\n",
       "        [ 3346,  3854],\n",
       "        [ 4026,  4524],\n",
       "        [ 5820,  6220],\n",
       "        [ 6273,  6747],\n",
       "        [ 6877,  7439],\n",
       "        [ 7509,  7593],\n",
       "        [ 7653,  7860],\n",
       "        [ 7898,  8110],\n",
       "        [14740, 15810]], dtype=uint16),\n",
       " 'REMstate': array([[ 3242,  3313],\n",
       "        [ 3855,  3994],\n",
       "        [ 6748,  6833],\n",
       "        [ 7440,  7480],\n",
       "        [ 7594,  7613],\n",
       "        [ 7861,  7878],\n",
       "        [15811, 15886]], dtype=uint16)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_state_dict[\"ints\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,  1806],\n",
       "       [ 2947,  3015],\n",
       "       [ 3314,  3345],\n",
       "       [ 3995,  4025],\n",
       "       [ 4525,  5819],\n",
       "       [ 6221,  6272],\n",
       "       [ 6834,  6876],\n",
       "       [ 7481,  7508],\n",
       "       [ 7614,  7652],\n",
       "       [ 7879,  7897],\n",
       "       [ 8111, 14739],\n",
       "       [15887, 21006]], dtype=uint16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wake_state = sleep_state_dict[\"ints\"][\"WAKEstate\"]\n",
    "wake_state  # This is the start time and the end time of the wake state. Probably in frames."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need to confirm the units and this can go as a `TimeIntervals` in a processing module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Behavior`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = file_path.parent / \"e13_16f1_210302.Behavior.mat\" \n",
    "file_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'behavior_dict.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly this contains a date in `date` and subject information in `animal`.\n",
    "Surprisingly, this does not seem to contain any large vector as I expected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ripples.events.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"e13_16f1_210302.ripples.events.mat\"\n",
    "file_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'riples.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large file. We need to look into the paper to see what should be stored from here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `chanMap.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"chanMap.mat'\"\n",
    "file_path.is_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this to a file for visualization\n",
    "with open(json_directory / 'chanMap.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some time series here but no information about the channels as I was expecting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"e13_16f1_210302.session.mat\"\n",
    "file_path.is_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'session.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains useful information like subject, animal and an epoch file.\n",
    "Probably less relevant is information about other sources of data such as spikesorting and some of the analogous channels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spikesorting \n",
    "\n",
    "## Testing CellExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heberto/miniconda3/envs/neuroconv_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No e13_16f1_210302.sessionInfo.mat file found in the folder!\n"
     ]
    }
   ],
   "source": [
    "from spikeinterface.extractors import CellExplorerSortingExtractor\n",
    "\n",
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.spikes.cellinfo.mat\"\n",
    "try:\n",
    "    extractor = CellExplorerSortingExtractor(file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `sessionInfo` for this file so the above throws an assertion. Let's see what each of the files.\n",
    "\n",
    "The `CellExplorerSortingExtractor` uses the `sessionInfo` to extract the sampling frequency. But that might be somehwere else. \n",
    "\n",
    "Importantly, the files should contain the fields `UID` and `times` in a field called `spikes`. Let's see if any of the files contain this information and if it is consistent across them\n",
    "\n",
    "After a second look and some comunication with Petersen it seems that we can use the `spikes.cellinfo` file. We can modify the `CellExplorerSortingExtractor` to use this file instead of the `sessionInfo` file to extract sampling rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual spike files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spikes.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.spikes.cellinfo.mat\"\n",
    "\n",
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'spikes.cellinfo.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'ts', 'times', 'cluID', 'maxWaveformCh', 'maxWaveformCh1', 'phy_amp', 'total', 'amplitudes', 'basename', 'numcells', 'UID', 'sr', 'shankID', 'rawWaveform', 'filtWaveform', 'rawWaveform_all', 'rawWaveform_std', 'filtWaveform_all', 'filtWaveform_std', 'timeWaveform', 'timeWaveform_all', 'peakVoltage', 'channels_all', 'peakVoltage_sorted', 'maxWaveform_all', 'peakVoltage_expFitLengthConstant', 'processinginfo'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes = mat_file[\"spikes\"]\n",
    "spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,\n",
       " (135,),\n",
       " (135,),\n",
       " (135,),\n",
       " array([1, 2, 3], dtype=uint8),\n",
       " array([ 119, 1162, 1167], dtype=uint16),\n",
       " array([ 68.71136667, 255.81043333, 256.2958    ]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = spikes[\"sr\"]\n",
    "cluster_id = spikes[\"cluID\"]\n",
    "times = spikes[\"times\"]\n",
    "unit_ids = spikes[\"UID\"]\n",
    "\n",
    "sampling_rate, cluster_id.shape, times.shape, unit_ids.shape, unit_ids[:3], cluster_id[:3], times[:3][0][:3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cell_metrics.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.cell_metrics.cellinfo.mat\"\n",
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Ouput to an external file\n",
    "with open(json_directory / 'cell_metrics.cellinfo.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " (135,),\n",
       " (135,),\n",
       " (135,),\n",
       " array([ 119, 1162, 1167], dtype=uint16),\n",
       " array([ 119, 1162, 1167], dtype=uint16),\n",
       " array([ 68.71136667, 255.81043333, 256.2958    ]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = mat_file[\"cell_metrics\"][\"spikes\"][\"times\"]\n",
    "unit_ids = mat_file[\"cell_metrics\"][\"UID\"]\n",
    "unit_ids = mat_file[\"cell_metrics\"][\"cluID\"]\n",
    "sampling_rate = None \n",
    "\n",
    "sampling_rate, cluster_id.shape, times.shape, unit_ids.shape, unit_ids[:3], cluster_id[:3], times[:3][0][:3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mono_ress.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.mono_res.cellinfo.mat\"\n",
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'mono_res.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somet other analysis concerning `Monosynaptic connections.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cellexplorer with `spikes.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import CellExplorerSortingExtractor\n",
    "\n",
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.spikes.cellinfo.mat\"\n",
    "\n",
    "try:\n",
    "    extractor = CellExplorerSortingExtractor(file_path, sampling_frequency=30_000.0)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([      106,       132,       168, ..., 630229202, 630229228,\n",
       "         630229390]),\n",
       "  array([  3,  45,   2, ...,  65, 124,   5], dtype=uint8))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.get_all_spike_trains()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to extract the sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_matfile_path = file_path\n",
    "import scipy \n",
    "import hdf5storage\n",
    "\n",
    "try:\n",
    "    spikes_mat = scipy.io.loadmat(file_name=str(spikes_matfile_path))\n",
    "    read_spikes_info_with_scipy = True\n",
    "except NotImplementedError:\n",
    "    spikes_mat = hdf5storage.loadmat(file_name=str(spikes_matfile_path))\n",
    "    read_spikes_info_with_scipy = False\n",
    "cell_info = spikes_mat.get(\"spikes\", np.empty(0))\n",
    "cell_info_fields = cell_info.dtype.names\n",
    "\n",
    "sampling_rate = float(cell_info[\"sr\"][0][0][0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroconv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
