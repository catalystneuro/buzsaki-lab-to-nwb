{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "\n",
    "# from mat73 import loadmat as loadmat_mat73\n",
    "# from mat4py import loadmat as loadmat_mat4py\n",
    "\n",
    "import h5py\n",
    "from scipy.io import loadmat as loadmat_scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session analysis\n",
    "Let's start with a session to look at the files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and their description. A first take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.SleepState.states.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.ripples.events.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.cell_metrics.cellinfo.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/chanMap.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.spikes.cellinfo.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.Behavior.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.mono_res.cellinfo.mat'),\n",
       " PosixPath('/home/heberto/buzaki/e13_16f1_210302/e13_16f1_210302.session.mat')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_path = Path(\"/home/heberto/buzaki/e13_16f1_210302/\")\n",
    "session_files_path_list = list(session_path.iterdir())\n",
    "session_files_path_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as Cody mention, we have seen some experimental data from this lab already and we are familiar with the names.\n",
    "\n",
    "In a [previous conversion](https://github.com/catalystneuro/buzsaki-lab-to-nwb/blob/master/buzsaki_lab_to_nwb/yuta_visual_cortex/files_documentation.ipynb) I found out that the matlab files contain the following information:\n",
    "\n",
    "\n",
    "\n",
    "* `SleepState.states` : This can be considered processed data involving up-down intervals. This can be include as process data.\n",
    "* `chanMap` : This seems to be concerned with information of the channels in the electrode. For example we find both the x and y coordinates of each of the channels. The structure of the files here is (1, n_channels) where n_channels is 64 for this setup.\n",
    "* `session` : Contains behavioral info and general information related to the session such as the experimenter, the species, the strain and timestamps for the creation of the session.\n",
    "\n",
    "As you see, we have the following descriptions missing:\n",
    "* `.ripples.events.mat`: \n",
    "* `Behavior` : \n",
    "\n",
    "Which is something that we would do below.\n",
    "\n",
    "#### Spike sorting\n",
    "The files related to spike sorting were the following in a previous conversion.\n",
    "\n",
    "For the previous conversion those were the files related to **cell explorer format / interface**:\n",
    "* `metric_cell_info`\n",
    "* `mono_res_cellinfo`\n",
    "* `spikes.cell_info`\n",
    "\n",
    "They don't seem equivalent to the ones here. We need to confirm that they are equivalent to the following files in this conversion:\n",
    "* `cell_metrics.cellinfo.mat`\n",
    "* `cell_metrics.cellinfo`\n",
    "* `spikes.cellinfo`\n",
    "\n",
    "This is done below.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring some files\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SleepState.states`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see now which matlab file opener works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__header__ <class 'bytes'>\n",
      "__version__ <class 'str'>\n",
      "__globals__ <class 'list'>\n",
      "SleepState <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"e13_16f1_210302.SleepState.states.mat\"\n",
    "# Open file_path with loadmat_scipy from scipy\n",
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "# Iterate over the keys and print the type of the values\n",
    "for key in mat_file.keys():\n",
    "    print(key, type(mat_file[key]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a recursive structure. Let's print the keys, types and shapes (if numpy array) for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_keys_and_types(dictionary):\n",
    "    output_dict = {}\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, dict):\n",
    "            output_dict[key] = build_keys_and_types(value)\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            if value.size > 10:\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'shape': str(value.shape)\n",
    "                }\n",
    "            else:\n",
    "                # Print small arrays\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'value': str(value)\n",
    "                }\n",
    "        elif isinstance(value, list):\n",
    "            if len(value) > 10:\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'length': len(value)\n",
    "                }\n",
    "            else:\n",
    "                # Print small lists\n",
    "                output_dict[key] = {\n",
    "                    'type': str(type(value)),\n",
    "                    'value': str(value)\n",
    "                }\n",
    "        else:\n",
    "            output_dict[key] = {\n",
    "                \"type\": str(type(value)),\n",
    "                \"value\": str(value),\n",
    "            }\n",
    "    return output_dict\n",
    "\n",
    "# Define your sleep_state_dict here\n",
    "\n",
    "result = build_keys_and_types(mat_file)\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "# Dump to a file in the same folder\n",
    "json_directory = Path.cwd() / \"_json_files\"\n",
    "json_directory.mkdir(exist_ok=True)\n",
    "with open(json_directory / 'sleep_state_dict.json', 'w') as f:\n",
    "    f.write(json_output)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a matlab licence, you can also just explore the file there. There are two things to look for, large arrays that might\n",
    "correspond to behavorial data and metadata from the experiment.\n",
    "\n",
    "Because I know the data from this lab I will be looking for the REM state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_state_dict = mat_file[\"SleepState\"]\n",
    "json_dict = json.dumps(build_keys_and_types(sleep_state_dict), indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WAKEstate': array([[    1,  1806],\n",
       "        [ 2947,  3015],\n",
       "        [ 3314,  3345],\n",
       "        [ 3995,  4025],\n",
       "        [ 4525,  5819],\n",
       "        [ 6221,  6272],\n",
       "        [ 6834,  6876],\n",
       "        [ 7481,  7508],\n",
       "        [ 7614,  7652],\n",
       "        [ 7879,  7897],\n",
       "        [ 8111, 14739],\n",
       "        [15887, 21006]], dtype=uint16),\n",
       " 'NREMstate': array([[ 1807,  2946],\n",
       "        [ 3016,  3241],\n",
       "        [ 3346,  3854],\n",
       "        [ 4026,  4524],\n",
       "        [ 5820,  6220],\n",
       "        [ 6273,  6747],\n",
       "        [ 6877,  7439],\n",
       "        [ 7509,  7593],\n",
       "        [ 7653,  7860],\n",
       "        [ 7898,  8110],\n",
       "        [14740, 15810]], dtype=uint16),\n",
       " 'REMstate': array([[ 3242,  3313],\n",
       "        [ 3855,  3994],\n",
       "        [ 6748,  6833],\n",
       "        [ 7440,  7480],\n",
       "        [ 7594,  7613],\n",
       "        [ 7861,  7878],\n",
       "        [15811, 15886]], dtype=uint16)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_state_dict[\"ints\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,  1806],\n",
       "       [ 2947,  3015],\n",
       "       [ 3314,  3345],\n",
       "       [ 3995,  4025],\n",
       "       [ 4525,  5819],\n",
       "       [ 6221,  6272],\n",
       "       [ 6834,  6876],\n",
       "       [ 7481,  7508],\n",
       "       [ 7614,  7652],\n",
       "       [ 7879,  7897],\n",
       "       [ 8111, 14739],\n",
       "       [15887, 21006]], dtype=uint16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wake_state = sleep_state_dict[\"ints\"][\"WAKEstate\"]\n",
    "wake_state  # This is the start time and the end time of the wake state. Probably in frames."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need to confirm the units and this can go as a `TimeIntervals` in a processing module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Behavior`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = file_path.parent / \"e13_16f1_210302.Behavior.mat\" \n",
    "file_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'behavior_dict.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly this contains a date in `date` and subject information in `animal`.\n",
    "Surprisingly, this does not seem to contain any large vector as I expected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ripples.events.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"e13_16f1_210302.ripples.events.mat\"\n",
    "file_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'riples.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large file. We need to look into the paper to see what should be stored from here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `chanMap.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"chanMap.mat'\"\n",
    "file_path.is_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this to a file for visualization\n",
    "with open(json_directory / 'chanMap.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some time series here but no information about the channels as I was expeting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = session_files_path_list[0]\n",
    "file_path = file_path.parent / \"e13_16f1_210302.session.mat\"\n",
    "file_path.is_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'session.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains useful information like subject, animal and an epoch file.\n",
    "Probably less relevant is information about other sources of data such as spikesorting and some of the analogous channels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spikesorting \n",
    "\n",
    "## Testing CellExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heberto/miniconda3/envs/neuroconv_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "No e13_16f1_210302.sessionInfo.mat file found in the folder!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspikeinterface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextractors\u001b[39;00m \u001b[39mimport\u001b[39;00m CellExplorerSortingExtractor\n\u001b[1;32m      3\u001b[0m file_path \u001b[39m=\u001b[39m session_files_path_list[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mparent \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39me13_16f1_210302.spikes.cellinfo.mat\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m extractor \u001b[39m=\u001b[39m CellExplorerSortingExtractor(file_path)\n",
      "File \u001b[0;32m~/development/spikeinterface/src/spikeinterface/extractors/cellexplorersortingextractor.py:54\u001b[0m, in \u001b[0;36mCellExplorerSortingExtractor.__init__\u001b[0;34m(self, spikes_matfile_path, session_info_matfile_path, sampling_frequency)\u001b[0m\n\u001b[1;32m     52\u001b[0m     session_info_matfile_path \u001b[39m=\u001b[39m folder_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msorting_id\u001b[39m}\u001b[39;00m\u001b[39m.sessionInfo.mat\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m session_info_matfile_path \u001b[39m=\u001b[39m Path(session_info_matfile_path)\n\u001b[0;32m---> 54\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m     55\u001b[0m     (session_info_matfile_path)\u001b[39m.\u001b[39mis_file()\n\u001b[1;32m     56\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo \u001b[39m\u001b[39m{\u001b[39;00msorting_id\u001b[39m}\u001b[39;00m\u001b[39m.sessionInfo.mat file found in the folder!\u001b[39m\u001b[39m\"\u001b[39m \n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     session_info_mat \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(file_name\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(session_info_matfile_path))\n",
      "\u001b[0;31mAssertionError\u001b[0m: No e13_16f1_210302.sessionInfo.mat file found in the folder!"
     ]
    }
   ],
   "source": [
    "from spikeinterface.extractors import CellExplorerSortingExtractor\n",
    "\n",
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.spikes.cellinfo.mat\"\n",
    "extractor = CellExplorerSortingExtractor(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `sessionInfo` for this file so the above throws an assertion. Let's see what each of the files.\n",
    "\n",
    "The `CellExplorerSortingExtractor` uses the `sessionInfo` to extract the sampling frequency. But that might be somehwere else. \n",
    "\n",
    "Importantly, the files should contain the fields `UID` and `times` in a field called `spikes`. Let's see if any of the files contain this information and if it is consistent across them\n",
    "\n",
    "Looking at the files below, they do seem to agree with the basic information. It should be straighforward to role a new sorting extractor for this dataset. Or use NumpySortingExtractor and then add the `sessionInfo` manually. Not sure at this point on what it would be easier. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual spike files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spikes.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.spikes.cellinfo.mat\"\n",
    "\n",
    "mat_file = loadmat_scipy(file_path, simplify_cells=True)\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'cellinfo.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = mat_file[\"spikes\"]\n",
    "spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = spikes[\"sr\"]\n",
    "cluster_id = spikes[\"cluID\"]\n",
    "times = spikes[\"times\"]\n",
    "unit_ids = spikes[\"UID\"]\n",
    "\n",
    "sampling_rate, cluster_id.shape, times.shape, unit_ids.shape, unit_ids[:3], cluster_id[:3], times[:3][0][:3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cell_metrics.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.cell_metrics.cellinfo.mat\"\n",
    "\n",
    "# Ouput to an external file\n",
    "with open(json_directory / 'cell_metrics.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = mat_file[\"spikes\"]\n",
    "spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = spikes[\"sr\"]\n",
    "cluster_id = spikes[\"cluID\"]\n",
    "times = spikes[\"times\"]\n",
    "unit_ids = spikes[\"UID\"]\n",
    "\n",
    "sampling_rate, cluster_id.shape, times.shape, unit_ids.shape, unit_ids[:3], cluster_id[:3], times[:3][0][:3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mono_ress.cellinfo.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = session_files_path_list[0].parent / \"e13_16f1_210302.mono_res.cellinfo.mat\"\n",
    "\n",
    "# Output to an external file\n",
    "with open(json_directory / 'mono_res.json', 'w') as f:\n",
    "    f.write(json.dumps(build_keys_and_types(mat_file), indent=4))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = mat_file[\"spikes\"]\n",
    "spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = spikes[\"sr\"]\n",
    "cluster_id = spikes[\"cluID\"]\n",
    "times = spikes[\"times\"]\n",
    "unit_ids = spikes[\"UID\"]\n",
    "\n",
    "sampling_rate, cluster_id.shape, times.shape, unit_ids.shape, unit_ids[:3], cluster_id[:3], times[:3][0][:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroconv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
