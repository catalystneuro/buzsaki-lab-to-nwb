{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f304f4e-6fc3-4168-b759-2261726e7ec8",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "The purpose of this notebook is to describe the files available in the data repository and their structure. \n",
    "\n",
    "For version control purposes this file should be commited without output and only run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4115eb-560c-4ad4-bc31-45556c592113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6855715-5b8a-494c-ac27-0d063d03a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matlab_file(file_path):\n",
    "    file_path = str(file_path)\n",
    "\n",
    "    try:\n",
    "        mat_file = loadmat_mat4py(str(file_path))\n",
    "        mat_file['read'] = 'mat4py'\n",
    "    except:\n",
    "        try:\n",
    "            mat_file = loadmat_mat73(file_path)\n",
    "            mat_file['read'] = 'mat73'\n",
    "        except:\n",
    "            mat_file = loadmat_scipy(file_path)\n",
    "            mat_file['read'] = 'scipy'\n",
    "    return mat_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f7cbc-80b6-4628-84c1-bd608a01d2e3",
   "metadata": {},
   "source": [
    "# Data directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc629d6-2fcd-4f18-8d8f-31dca9bb9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/shared/catalystneuro/Buzsaki/TingleyD')  # Change this with the right location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946738c4-f490-431f-8cf2-a31243efd706",
   "metadata": {},
   "source": [
    "## Subjects \n",
    "First, let's get the different subjects and filter the ones that we decide shoule be included in this transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1beb32-822c-4d19-8bbb-0b890a0fc73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DT8', 'DT2', 'DT9', 'DT5', 'DT7'])\n"
     ]
    }
   ],
   "source": [
    "subjects_in_study = ['DT2', 'DT5', 'DT7', 'DT8', 'DT9']\n",
    "subject_path_dic = {p.stem:p for p in base_path.iterdir() if p.is_dir() and p.name in subjects_in_study}\n",
    "pprint(subject_path_dic.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d9848-2677-41ff-8742-bf5f1a819934",
   "metadata": {},
   "source": [
    "The results of this should be all the subjects in this paper\n",
    "['DT2', 'DT5', 'DT7', 'DT8', 'DT9'] and the dictionary values are the paths for each of the subjects folder. \n",
    "\n",
    "Now, it happens that this particular project has a large amount of data. We calculate the folder of each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb486b5-489f-4c78-b69a-7c2ecac84079",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_sizes_pairs = [(subject, sum([p.stat().st_size for p in path.rglob('*')])) for (subject, path) in subject_path_dic.items()]\n",
    "\n",
    "for subject, size in subject_sizes_pairs:\n",
    "    print(f\"{subject} directory size is {size / (1000 ** 4) :2.2f} TB and {size / (1025 ** 4) :2.2f} TiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd37e30-247c-423b-a9ed-153f20fc2816",
   "metadata": {},
   "source": [
    "The code above should output this:\n",
    "\n",
    "    DT8 directory size is 0.54 TB and 0.49 TiB\n",
    "    DT2 directory size is 4.18 TB and 3.79 TiB\n",
    "    DT9 directory size is 0.83 TB and 0.75 TiB\n",
    "    DT5 directory size is 1.83 TB and 1.66 TiB\n",
    "    DT7 directory size is 1.08 TB and 0.98 TiB\n",
    "\n",
    "The directory associated to subject `DT2` for example is 4.18 terabytes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507d9af-7155-43e2-a178-9d74140a3499",
   "metadata": {},
   "source": [
    "## Sessions\n",
    "Now let's see how the sessions are structure. For this dataset we have that each subject contains multiple files, tentatively belonging to different seessions and some top level files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0e478-df50-40e7-a839-2beed3ad000c",
   "metadata": {},
   "source": [
    "### Session folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a60f4a6f-8be5-4ba5-a448-87d4fce3a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712',\n",
      " 'DT2_rPPC_rCCG_144um_72um_20160207_160207_170623',\n",
      " 'DT2_rPPC_rCCG_2016um_290um_20160214_160214_105540',\n",
      " 'DT2_rPPC_rCCG_218um_218um_20160208_160208_142910',\n",
      " 'DT2_rPPC_rCCG_3036um_362um_20160215_160215_122710',\n",
      " 'DT2_rPPC_rCCG_3108um_434um_20160215_160215_161846',\n",
      " 'DT2_rPPC_rCCG_3324um_1000um_20160217_160217_103121',\n",
      " 'DT2_rPPC_rCCG_3324um_1072um_20160218_160218_133625',\n",
      " 'DT2_rPPC_rCCG_3324um_1144um_20160219_160219_130435',\n",
      " 'DT2_rPPC_rCCG_3324um_650um_20160216_160216_132620',\n",
      " 'DT2_rPPC_rCCG_3324um_794um_20160216_160216_163304',\n",
      " 'DT2_rPPC_rCCG_3396um_1180um_20160220_160220_141839',\n",
      " 'DT2_rPPC_rCCG_3396um_1180um_20160221_160221_135947',\n",
      " 'DT2_rPPC_rCCG_3468um_1216um_20160222_160222_120902',\n",
      " 'DT2_rPPC_rCCG_3468um_1216um_20160223_160223_121321',\n",
      " 'DT2_rPPC_rCCG_3468um_1216um_20160223_160223_173937',\n",
      " 'DT2_rPPC_rCCG_3468um_1216um_20160224_160224_133121',\n",
      " 'DT2_rPPC_rCCG_3468um_1216um_20160225_160225_130701',\n",
      " 'DT2_rPPC_rCCG_3468um_1252um_20160226_160226_124132',\n",
      " 'DT2_rPPC_rCCG_3540um_1288um_20160227_160227_121226',\n",
      " 'DT2_rPPC_rCCG_3540um_1288um_20160228_160228_135001',\n",
      " 'DT2_rPPC_rCCG_3612um_1360um_20160302_160302_134841',\n",
      " 'DT2_rPPC_rCCG_3612um_1360um_20160303_160303_084915',\n",
      " 'DT2_rPPC_rCCG_3612um_1360um_20160304_160304_150220',\n",
      " 'DT2_rPPC_rCCG_3612um_1360um_20160305_160305_141507',\n",
      " 'DT2_rPPC_rCCG_362um_218um_20160209_160209_183610',\n",
      " 'DT2_rPPC_rCCG_650um_218um_20160210_160210_120100',\n",
      " 'DT2_rPPC_rCCG_794um_290um_20160210_160210_225301',\n",
      " 'DT2_rPPC_rCCG_938um_290um_20160212_160212_122801',\n",
      " 'z_Intruder_test_160304_152951',\n",
      " 'z_USV_test_3612um_1360um_20160307_160307_202140',\n",
      " 'z_novel_cage_test_160227_165229']\n"
     ]
    }
   ],
   "source": [
    "subject = \"DT8\" \n",
    "sessions_path_in_subject = {p.stem:p for p in subject_path_dic[subject].iterdir() if p.is_dir()}\n",
    "session_names_list = list(sessions_path_in_subject.keys())\n",
    "session_names_list.sort()\n",
    "pprint(session_names_list, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521ea32-a773-4888-8b92-02780f43773c",
   "metadata": {},
   "source": [
    "The results should be something like:\n",
    "    \n",
    "    ['20170124_0um_0um_170124_151501',\n",
    "     '20170125_0um_0um_merge',\n",
    "     '20170126_0um_0um_merge',\n",
    "     '20170127_0um_0um_170127_121658',\n",
    "     '20170128_0um_72um_merge',\n",
    "     '20170129_0um_72um_170129_130356',\n",
    "     '20170130_0um_144um_170130_143246',\n",
    "     '20170131_72um_432um_merge',\n",
    "     '20170201_72um_432um_merge',\n",
    "     '20170202_72um_576um_170202_092033',\n",
    "     '20170203_72um_648um_170203_105608',\n",
    "     '20170206_72um_1872um_merge',\n",
    "     '20170207_144um_1944um_merge',\n",
    "     '20170208_144um_1944um_merge',\n",
    "     '20170209_144um_1944um_merge',\n",
    "     '20170210_144um_1944um_170210_112254',\n",
    "     '20170211_144um_1944um_merge',\n",
    "     '20170212_144um_1944um_170212_154634',\n",
    "     '20170213_144um_1944um_merge',\n",
    "     '20170214_216um_1944um_170214_102804',\n",
    "     '20170215_216um_1944um_170215_140739',\n",
    "     '20170216_216um_1944um_merge',\n",
    "     '20170217_216um_1944um_merge',\n",
    "     '20170218_216um_1944um_170218_114724',\n",
    "     '20170220_216um_1944um_170220_192456',\n",
    "     '20170221_324um_1944um_170221_101929',\n",
    "     '20170222_324um_2088um_170222_113940',\n",
    "     '20170223_324um_2088um_170223_103741',\n",
    "     '20170224_324um_2088um_170224_101710',\n",
    "     '20170227_324um_2088um_170227_105926',\n",
    "     '20170228_324um_2088um_merge',\n",
    "     '20170229_324um_2088um_merge',\n",
    "     '20170303_324um_2088um_170303_114804',\n",
    "     '20170305_468um_2088um_170305_135233',\n",
    "     '20170306_468um_2088um_170306_113628',\n",
    "     '20170307_540um_2088um_merge',\n",
    "     '20170308_612um_2088um_merge',\n",
    "     '20170309_612um_2088um_170309_093245',\n",
    "     '20170310_612um_2088um_170310_140825',\n",
    "     '20170311_684um_2088um_170311_134350',\n",
    "     '20170316_828um_2088um_170316_093559',\n",
    "     '20170318_828um_2088um_170318_201151',\n",
    "     '20170320_828um_2088um_170320_200023']\n",
    "\n",
    "Which seem to be the different recording sessions with the following format:\n",
    " * `{date}_{x}um_{date_time |merge}`\n",
    " \n",
    " The only subject that does not adapt to this format is subject `DT2`. Here the files have a different format:\n",
    " \n",
    "     ['DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712',\n",
    "     'DT2_rPPC_rCCG_144um_72um_20160207_160207_170623',\n",
    "     'DT2_rPPC_rCCG_2016um_290um_20160214_160214_105540',\n",
    "     'DT2_rPPC_rCCG_218um_218um_20160208_160208_142910',\n",
    "     'DT2_rPPC_rCCG_3036um_362um_20160215_160215_122710',\n",
    "     'DT2_rPPC_rCCG_3108um_434um_20160215_160215_161846',\n",
    "     'DT2_rPPC_rCCG_3324um_1000um_20160217_160217_103121',\n",
    "     'DT2_rPPC_rCCG_3324um_1072um_20160218_160218_133625',\n",
    "     'DT2_rPPC_rCCG_3324um_1144um_20160219_160219_130435',\n",
    "     'DT2_rPPC_rCCG_3324um_650um_20160216_160216_132620',\n",
    "     'DT2_rPPC_rCCG_3324um_794um_20160216_160216_163304',\n",
    "     'DT2_rPPC_rCCG_3396um_1180um_20160220_160220_141839',\n",
    "     'DT2_rPPC_rCCG_3396um_1180um_20160221_160221_135947',\n",
    "     'DT2_rPPC_rCCG_3468um_1216um_20160222_160222_120902',\n",
    "     'DT2_rPPC_rCCG_3468um_1216um_20160223_160223_121321',\n",
    "     'DT2_rPPC_rCCG_3468um_1216um_20160223_160223_173937',\n",
    "     'DT2_rPPC_rCCG_3468um_1216um_20160224_160224_133121',\n",
    "     'DT2_rPPC_rCCG_3468um_1216um_20160225_160225_130701',\n",
    "     'DT2_rPPC_rCCG_3468um_1252um_20160226_160226_124132',\n",
    "     'DT2_rPPC_rCCG_3540um_1288um_20160227_160227_121226',\n",
    "     'DT2_rPPC_rCCG_3540um_1288um_20160228_160228_135001',\n",
    "     'DT2_rPPC_rCCG_3612um_1360um_20160302_160302_134841',\n",
    "     'DT2_rPPC_rCCG_3612um_1360um_20160303_160303_084915',\n",
    "     'DT2_rPPC_rCCG_3612um_1360um_20160304_160304_150220',\n",
    "     'DT2_rPPC_rCCG_3612um_1360um_20160305_160305_141507',\n",
    "     'DT2_rPPC_rCCG_362um_218um_20160209_160209_183610',\n",
    "     'DT2_rPPC_rCCG_650um_218um_20160210_160210_120100',\n",
    "     'DT2_rPPC_rCCG_794um_290um_20160210_160210_225301',\n",
    "     'DT2_rPPC_rCCG_938um_290um_20160212_160212_122801',\n",
    "\n",
    " It seems that the general format is `DT2_rPPC_rCCG_{x}_um_{y}_um_{date}_{time_stamp}_{time_stamp}`. It is not clear yet to me what is the meaning of the second timestamp. Possibility is a notation for an interval and the second one indicates the duration. That is, a (start, duration) interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a178ed28-37b3-40f0-b752-06138a6b6e4a",
   "metadata": {},
   "source": [
    "## Structure of the session directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb151be-93b5-420d-963d-46d6a1fc5019",
   "metadata": {},
   "source": [
    "Now let's look inside the directory of those directories inside the session path. \n",
    "Let's show some examples taken from the list above for subject DT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3e15198-fb47-4066-b6d9-66779e17667b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'20170124_0um_0um_170124_151501'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_379/26525608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msession_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"20170124_0um_0um_170124_151501\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpath_of_dirs_in_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions_path_in_subject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdirectories_in_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_of_dirs_in_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdirectories_in_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectories_in_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '20170124_0um_0um_170124_151501'"
     ]
    }
   ],
   "source": [
    "session_name = \"20170124_0um_0um_170124_151501\" \n",
    "path_of_dirs_in_session = {p.name:p for p in sessions_path_in_subject[session_name].iterdir() if p.is_dir()}\n",
    "directories_in_session = list(path_of_dirs_in_session.keys())\n",
    "directories_in_session.sort(key=lambda x:int(x))\n",
    "pprint(directories_in_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3229993-05f6-4e85-8e24-ad336feae299",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name = \"20170224_324um_2088um_170224_101710\"\n",
    "path_of_dirs_in_session = {p.name:p for p in sessions_path_in_subject[session_name].iterdir() if p.is_dir()}\n",
    "directories_in_session = list(path_of_dirs_in_session.keys())\n",
    "directories_in_session.sort()\n",
    "pprint(directories_in_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7222099-f1f1-4339-a146-3323495fc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name = \"20170307_540um_2088um_merge\" \n",
    "path_of_dirs_in_session = {p.name:p for p in sessions_path_in_subject[session_name].iterdir() if p.is_dir()}\n",
    "directories_in_session = list(path_of_dirs_in_session.keys())\n",
    "directories_in_session.sort()\n",
    "pprint(directories_in_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d13ac-7f65-4580-9f1f-b7e3c0fb7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name =\"20170308_612um_2088um_merge\"  \n",
    "path_of_dirs_in_session = {p.name:p for p in sessions_path_in_subject[session_name].iterdir() if p.is_dir()}\n",
    "directories_in_session = list(path_of_dirs_in_session.keys())\n",
    "directories_in_session.sort()\n",
    "pprint(directories_in_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6c472-7318-4468-ae9f-534992cac2cc",
   "metadata": {},
   "source": [
    "The output of the last example should be something like this:\n",
    "\n",
    "    ['1',\n",
    "     '2',\n",
    "     '3',\n",
    "     '4',\n",
    "     '5',\n",
    "     '6',\n",
    "     '7',\n",
    "     '8',\n",
    "     '9',\n",
    "     '10',\n",
    "     '20170308_612um_2088um_170308_115428', # these are available on merge sessions\n",
    "     '20170308_612um_2088um_170308_144851', # there are available on merge sessions\n",
    "     'Session 2017-03-08', # not available in every session\n",
    "     'StateScoreFigures'   # not available in every session\n",
    "     ]\n",
    "\n",
    "The general structure seem to be the following. Each of the sessions contains ten folders numerated from 1 to 10. Merge sessions contain further folders wher the specific time-stamps of the merged sessions can be found and finally sometimes there is a folder with the naming \"Session {date}\" \n",
    "\n",
    "Importantly, while subject `DT5` has the same number, 10, of numbered folders the rest of the subject do not. `DT7` has 7 folders whereas `DT9` and `DT2` have 12 and 13 folders respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66863ad9-142f-466e-8db7-d0e09fedb5c2",
   "metadata": {},
   "source": [
    "### Files in each of the sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0ceb3-1629-4b2c-a68e-592ec9f6b0ce",
   "metadata": {},
   "source": [
    "Here a brief description of what type of files are each of the levels. A more extended discussion can be vound in the Data section below\n",
    "\n",
    "In the session directory top-most level the following formats can be found:\n",
    "* evt\n",
    "* clu\n",
    "* fet\n",
    "* pos\n",
    "* res\n",
    "* lfp\n",
    "* spk\n",
    "* nrs\n",
    "* xml\n",
    "* mat\n",
    "\n",
    "This seems to be where the main data for the session is, plus the mat files whereas both processing and behavioral might be.\n",
    "\n",
    "In the directories that are named with numbers the following formats can be found:\n",
    "* kwd \n",
    "* kwik\n",
    "* log\n",
    "* clu\n",
    "* fet\n",
    "* fmask\n",
    "* klg\n",
    "* prm\n",
    "* kvlog\n",
    "\n",
    "This seems the results of `klusta` suite for spike sorting and analysis\n",
    "\n",
    "In merge session when merge directories are available the following files can be found on them:\n",
    "* info.rhd\n",
    "* amplifiers.nrs\n",
    "* amplifiers.xlm\n",
    "\n",
    "Finally, when the directory \"Sesion {date}\" is available, it contains csv files with a time stamp as title and some `.tak` files which seem to be audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb52203-d9ea-49ad-898a-5789e764529e",
   "metadata": {},
   "source": [
    "## Subject top-level files\n",
    "Moreover, we also find some files in the topmost directory. We describe them in more detail in the data section of this document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84739b6-1aee-47d8-bb11-f92160e4f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_not_in_session = {p.name:p for p in subject_path_dic[subject].iterdir() if p.is_file()}\n",
    "files_names = list(files_not_in_session.keys())\n",
    "files_names.sort()\n",
    "pprint(files_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94bc40-d73b-4415-bcc4-2eb87a821269",
   "metadata": {},
   "source": [
    "The result should be something like this:\n",
    "\n",
    "    ['.DS_Store',\n",
    "     'DT8_current_dataset_parietal_theta.mat',\n",
    "     'behav.mat',\n",
    "     'groupRecordings.m']\n",
    "     \n",
    " They seem to be behavioral files and we will come back to them when we discuss the specific files below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80788b7c-9ae4-43fe-bffb-bbbbd658ddf6",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae14f0c-9305-4084-824e-bb0aca477631",
   "metadata": {},
   "source": [
    "## An overview of the available data\n",
    "We discuss now what formats are present before describing the files in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28aceaa-0960-4669-8394-4ea7e07b80f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.alg', '.avi', '.cat', '.clu', '.com', '.csv', '.dat', '.EMG', '.evt', '.fet',\n",
      " '.klg', '.kwd', '.kwx', '.led', '.lfp', '.LFP', '.lnk', '.log', '.LOG', '.low',\n",
      " '.mat', '.nrs', '.out', '.pos', '.prb', '.prm', '.raw', '.res', '.rhd', '.rLS',\n",
      " '.rls', '.spk', '.tak', '.txt', '.url', '.WAV', '.xml']\n"
     ]
    }
   ],
   "source": [
    "not_data_formats = [\".jpg\", \".png\", \".pdf\", \".svg\", \".fig\", \".py\", \".m\", '.py']\n",
    "\n",
    "format_list = [p.suffixes for p in base_path.rglob(\"*\") if p.is_file()]\n",
    "format_list = list({_ for suffixes in format_list for _ in suffixes}) \n",
    "format_list = [_ for _ in format_list if len(_)==4 and \" \" not in _]  # Only standar three letter formats.\n",
    "format_list = [_ for _ in format_list if not any(map(str.isdigit, _))]  # Remove numbers \n",
    "format_list = [_ for _ in format_list if _ not in not_data_formats] # remove data formts\n",
    "format_list.sort(key=lambda x : x.lower())  # sort by lower case\n",
    "\n",
    "pprint(format_list, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609333a3-f70c-4df2-86c8-e91f3b5ff7cb",
   "metadata": {},
   "source": [
    "The output of this should give us the formats available for this subject and should look something like this:\n",
    "\n",
    "    ['.alg', '.avi', '.cat', '.clu', '.com', '.csv', '.dat', '.EMG', '.evt', '.fet',\n",
    "     '.klg', '.kwd', '.kwx', '.led', '.lfp', '.LFP', '.lnk', '.log', '.LOG', '.low',\n",
    "     '.mat', '.nrs', '.out', '.pos', '.prb', '.prm', '.raw', '.res', '.rhd', '.rLS',\n",
    "     '.rls', '.spk', '.tak', '.txt', '.url', '.WAV', '.xml']\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c852fea-5762-4359-81d6-70dc81074d60",
   "metadata": {},
   "source": [
    "Descripton of the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d18931-e300-4cfa-8b69-3d125bfae362",
   "metadata": {},
   "source": [
    "* `.alg` :\n",
    "* `.avi` : video format.\n",
    "* `.cat` :\n",
    "* `.clu` : usually associated with the neuroscope sorting format\n",
    "* `.com` :\n",
    "* `.csv` : comma separated values.\n",
    "* `.dat` : usually the raw data.\n",
    "* `.EMG` : \n",
    "* `.evt` :\n",
    "* `.fet` :\n",
    "* `.klg` : files related to the klusta spike sorting suit.\n",
    "* `.kwd` : files related to the klusta spike sorting suit.\n",
    "* `.kwx` : files related to the klusta spike sorting suit.\n",
    "* `.led` :\n",
    "* `.lfp` : local field potential data.\n",
    "* `.LFP` : local field potential data\n",
    "* `.lnk` :\n",
    "* `.log` : log files, usually not useful. Sometimes associated with the Phy sorting program.\n",
    "* `.LOG` : log files, usually not useful.\n",
    "* `.low` : \n",
    "* `.mat` : data structures form matlab\n",
    "* `.nrs` :\n",
    "* `.out` :\n",
    "* `.pos` :\n",
    "* `.prb` :\n",
    "* `.prm` : \n",
    "* `.raw` :\n",
    "* `.res` : usually associated with the neuroscope sorting format\n",
    "* `.rhd` :\n",
    "* `.rLS` :\n",
    "* `.rls` :\n",
    "* `.spk` : \n",
    "* `.tak` : \n",
    "* `.txt` : plain text files\n",
    "* `.url` : a url address \n",
    "* `.WAV` : audio format.\n",
    "* `.xml` : xml files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712071a-482d-4fc8-85d6-a45ebf788522",
   "metadata": {},
   "source": [
    "## Dat file\n",
    "These files are usually raw data. However, for this project it seems that most files do not have the raw data and only have the lfp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9500cc14-70f3-4c70-8011-8fc5b495b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DT2/DT2_rPPC_rCCG_3612um_1360um_20160302_160302_134841/DT2_rPPC_rCCG_3612um_1360um_20160302_160302_134841.dat',\n",
      "  '76435.85 MB'),\n",
      " ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/analogin.dat',\n",
      "  '579.90 MB'),\n",
      " ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/supply.dat',\n",
      "  '1159.80 MB'),\n",
      " ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/time.dat',\n",
      "  '1159.80 MB'),\n",
      " ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712.dat',\n",
      "  '74226.95 MB'),\n",
      " ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/auxiliary.dat',\n",
      "  '3479.39 MB'),\n",
      " ('DT2/z_Intruder_test_160304_152951/z_Intruder_test_160304_152951.dat',\n",
      "  '51600.94 MB'),\n",
      " ('DT2/z_Intruder_test_160304_152951/extras/analogin.dat', '403.13 MB'),\n",
      " ('DT2/z_Intruder_test_160304_152951/extras/supply.dat', '806.26 MB'),\n",
      " ('DT2/z_Intruder_test_160304_152951/extras/time.dat', '806.26 MB')]\n"
     ]
    }
   ],
   "source": [
    "format_to_search = \".dat\"\n",
    "path_and_size_pairs = [('/'.join(str(p).split('/')[5:]), f\"{p.stat().st_size/1000**2:2.2f} MB\") for p in base_path.rglob(f\"*{format_to_search}\") if p.is_file()]\n",
    "pprint(path_and_size_pairs[:10], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d76e7-dd3d-4ec4-9efb-4a45f6baf44a",
   "metadata": {},
   "source": [
    "The output should be something like this:\n",
    "\n",
    "    [('DT2/DT2_rPPC_rCCG_3612um_1360um_20160302_160302_134841/DT2_rPPC_rCCG_3612um_1360um_20160302_160302_134841.dat',\n",
    "      '76435.85 MB'),\n",
    "     ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/analogin.dat',\n",
    "      '579.90 MB'),\n",
    "     ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/supply.dat',\n",
    "      '1159.80 MB'),\n",
    "     ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/time.dat',\n",
    "      '1159.80 MB'),\n",
    "     ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712.dat',\n",
    "      '74226.95 MB'),\n",
    "     ('DT2/DT2_rPPC_rCCG_1226um_290um_20160211_160213_120712/auxiliary.dat',\n",
    "      '3479.39 MB'),\n",
    "     ('DT2/z_Intruder_test_160304_152951/z_Intruder_test_160304_152951.dat',\n",
    "      '51600.94 MB'),\n",
    "     ('DT2/z_Intruder_test_160304_152951/extras/analogin.dat', '403.13 MB'),\n",
    "     ('DT2/z_Intruder_test_160304_152951/extras/supply.dat', '806.26 MB'),\n",
    "     ('DT2/z_Intruder_test_160304_152951/extras/time.dat', '806.26 MB')]\n",
    "\n",
    "Exploring the dat files above, we see that not all sessions have a .dat file, and that there are some .dat files that do not seem to correspond to sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35fb816-e7d7-4087-b338-99a07faa9ec5",
   "metadata": {},
   "source": [
    "## Matlab files\n",
    "As the matlab files are the ones usually associated with behavioral data they will be describe first. We will see what files are available on a sesion.\n",
    "Here we use a session with merger to have a picture of the most complicated case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "018102f1-cca6-4c35-90c2-aab052a34568",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sessions_path_in_subject' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9148/3348410464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msession_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"20170308_612um_2088um_merge\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmat_files_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions_path_in_subject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'mat'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmat_files_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_files_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmat_files_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_files_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sessions_path_in_subject' is not defined"
     ]
    }
   ],
   "source": [
    "session_name = \"20170308_612um_2088um_merge\"  \n",
    "mat_files_paths = {p.name:p for p in sessions_path_in_subject[session_name].rglob('*') if not p.is_dir() and 'mat' in ''.join(p.suffixes)}\n",
    "mat_files_names = list(mat_files_paths.keys())\n",
    "mat_files_names.sort()\n",
    "pprint(mat_files_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c19cd-600d-4240-bcc6-aa8d0cb5b11a",
   "metadata": {},
   "source": [
    "The file above should produce something like:\n",
    "\n",
    "    ['20170308_612um_2088um_merge.behavior.mat',\n",
    "     '20170308_612um_2088um_merge.firingMaps.cellinfo.mat',\n",
    "     '20170308_612um_2088um_merge.isolationMetrics.cellinfo.mat',\n",
    "     '20170308_612um_2088um_merge.olypherInfo.cellinfo.mat',\n",
    "     '20170308_612um_2088um_merge.phaseMaps.cellinfo.mat',\n",
    "     '20170308_612um_2088um_merge.placeFields.01_pctThresh.mat',\n",
    "     '20170308_612um_2088um_merge.placeFields.05_pctThresh.mat',\n",
    "     '20170308_612um_2088um_merge.placeFields.10_pctThresh.mat',\n",
    "     '20170308_612um_2088um_merge.placeFields.20_pctThresh.mat',\n",
    "     '20170308_612um_2088um_merge.placeFields.40_pctThresh.mat',\n",
    "     '20170308_612um_2088um_merge.positionDecodingGLM_binnedspace_box.cellinfo.mat',\n",
    "     '20170308_612um_2088um_merge.positionDecodingGLM_binnedspace_box_median.cellinfo.mat',\n",
    "     '20170308_612um_2088um_merge.positionDecodingMaxCorr_binned_box_median.cellinfo.mat',\n",
    "     '20170308_612um_2088um_merge.sessionInfo.mat',\n",
    "     '20170308_612um_2088um_merge.spikes.cellinfo.mat']\n",
    "     \n",
    "There are similar files in every section that look like {date}_{x}um_{x}.{name}.mat. We now look at all the files available for the subject disambiguation everything but the name at the end to see what is the variety of mat files available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfadc8-cb32-45aa-bf3e-986cd2a321f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files_names_simple = [name for name in mat_files_names if len(name.split(\".\")) == 2]\n",
    "mat_files_names_composed = ['.'.join(name.split('.')[1:]) for name in mat_files_names if len(name.split(\".\")) != 2]\n",
    "\n",
    "mat_files_names_formatted = list(set( mat_files_names_composed))\n",
    "mat_files_names_formatted += mat_files_names_simple\n",
    "mat_files_names_formatted.sort()\n",
    "pprint(mat_files_names_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b5d6b-49b8-427d-9f21-db089dc0ea56",
   "metadata": {},
   "source": [
    "This should produce something that looks like this:\n",
    "\n",
    "    ['DT8_current_dataset_parietal_theta.mat',\n",
    "    'PhaseLockingData.cellinfo.mat',\n",
    "    'assembliesCrossRegionData.mat',\n",
    "    'assembliesCrossRegionData_w_theta_sin_cos_coord_vel.mat',\n",
    "    'assembliesCrossRegion_split_w_theta.mat',\n",
    "    'assembliesWithinRegionData_w_theta_sin_cos_coord_vel.mat',\n",
    "    'behav.mat',\n",
    "    'behav_temp.mat',\n",
    "    'behavior.mat',\n",
    "    'firingMaps.cellinfo.mat',\n",
    "    'isolationMetrics.cellinfo.mat',\n",
    "    'ls_RipplePhaseModulation.cellinfo.mat',\n",
    "    'meta.mat',\n",
    "    'noiseCorrs.mat',\n",
    "    'olypherInfo.cellinfo.mat',g. Most likely we will ignore them.\n",
    "    `spk`\n",
    "    'olypherInfo_w_disc.cellinfo.mat',\n",
    "    'phaseMaps.cellinfo.mat',\n",
    "    'placeFields.01_pctThresh.mat',\n",
    "    'placeFields.05_pctThresh.mat',\n",
    "    'placeFields.10_pctThresh.mat',\n",
    "    'placeFields.20_pctThresh.mat',\n",
    "    'placeFields.40_pctThresh.mat',\n",
    "    'positionDecodingGLM.cellinfo.mat',\n",
    "    'positionDecodingGLM_binnedspace_box.cellinfo.mat',\n",
    "    'positionDecodingGLM_binnedspace_box_median.cellinfo.mat',\n",
    "    'positionDecodingGLM_binnedspace_box_nozero.cellinfo.mat',\n",
    "    'positionDecodingGLM_binnedspace_gauss.cellinfo.mat',\n",
    "    'positionDecodingGLM_box.cellinfo.mat',\n",
    "    'positionDecodingGLM_gaussian.cellinfo.mat',\n",
    "    'positionDecodingMaxCorr_binned_box_median.cellinfo.mat',\n",
    "    'referenceFrames.mat',\n",
    "    'sessionInfo.mat',\n",
    "    'spikes.cellinfo.mat']\n",
    "    \n",
    "Which gives us an idea of all the files available. I will describe them in more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27268665-e6fe-441b-a1a8-143d37c354f2",
   "metadata": {},
   "source": [
    "### Description overview (To-do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a6cce-1e4b-4ec2-a899-7d3a8a17ed54",
   "metadata": {},
   "source": [
    "* `DT8_current_dataset_parietal_theta.mat` :\n",
    "* `PhaseLockingData.cellinfo.mat` : \n",
    "* `assembliesCrossRegionData.mat` :  <- Check this\n",
    "* `assembliesCrossRegionData_w_theta_sin_cos_coord_vel.mat` :\n",
    "* `assembliesCrossRegion_split_w_theta.mat` :\n",
    "* `assembliesWithinRegionData_w_theta_sin_cos_coord_vel.mat` :\n",
    "* `behav.mat` : <- Check this\n",
    "* `behav_temp.mat` :\n",
    "* `behavior.mat` :\n",
    "* `firingMaps.cellinfo.mat` :\n",
    "* `isolationMetrics.cellinfo.mat` :\n",
    "* `ls_RipplePhaseModulation.cellinfo.mat` :\n",
    "* `meta.mat` :\n",
    "* `noiseCorrs.mat` : <Ignore this\n",
    "* `olypherInfo.cellinfo.mat` :\n",
    "* `olypherInfo_w_disc.cellinfo.mat` :\n",
    "* `phaseMaps.cellinfo.mat` :\n",
    "* `placeFields.01_pctThresh.mat` :\n",
    "* `placeFields.05_pctThresh.mat` :\n",
    "* `placeFields.10_pctThresh.mat` :\n",
    "* `placeFields.20_pctThresh.mat` :\n",
    "* `placeFields.40_pctThresh.mat` :\n",
    "* `positionDecodingGLM.cellinfo.mat` : Ignore all of these guys -we care about the ACTUAL position not the processing of it. Maybe the od have the x,y z, positions but more likely they are processing parameters for the anlalysis. \n",
    "* `positionDecodingGLM_binnedspace_box.cellinfo.mat` :\n",
    "* `positionDecodingGLM_binnedspace_box_median.cellinfo.mat` :\n",
    "* `positionDecodingGLM_binnedspace_box_nozero.cellinfo.mat` :\n",
    "* `positionDecodingGLM_binnedspace_gauss.cellinfo.mat` :\n",
    "* `positionDecodingGLM_box.cellinfo.mat` :\n",
    "* `positionDecodingGLM_gaussian.cellinfo.mat` :\n",
    "* `positionDecodingMaxCorr_binned_box_median.cellinfo.mat` :\n",
    "* `referenceFrames.mat` :\n",
    "* `sessionInfo.mat` : Initial the cell explorer sorter extrator in the folder paht where this file is. This header was missing from the Yuta file. It will not process the customer \n",
    "* `spikes.cellinfo.mat` :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2defd462-5e65-425c-b212-d8ab58680caf",
   "metadata": {},
   "source": [
    "## CSV files - To do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c78e4ae3-1e21-4dc6-adc0-6d13020ac74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Take 2017-02-20 07.26.44 PM', '24.45 MB'),\n",
      " ('Take 2017-02-01 05.02.41 PM', '39.27 MB'),\n",
      " ('Take 2017-03-07 03.11.44 PM_batch', '14.27 MB'),\n",
      " ('Take 2017-03-07 02.29.11 PM_batch', '30.21 MB'),\n",
      " ('Take 2017-03-07 03.11.44 PM', '13.43 MB'),\n",
      " ('Take 2017-03-07 02.29.11 PM', '28.50 MB'),\n",
      " ('Take 2017-02-17 01.48.32 PM', '64.16 MB'),\n",
      " ('Take 2017-02-08 01.04.32 PM', '25.19 MB'),\n",
      " ('Take 2017-02-08 01.47.29 PM', '15.13 MB'),\n",
      " ('Take 2017-02-08 01.42.33 PM', '1.76 MB')]\n"
     ]
    }
   ],
   "source": [
    "format_to_search = \".csv\"\n",
    "path_and_size_pairs = [(p.stem, f\"{p.stat().st_size/1000**2:2.2f} MB\") for p in base_path.rglob(f\"*{format_to_search}\") if p.is_file()]\n",
    "pprint(path_and_size_pairs[:10], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf2803-45e2-4a56-a445-184faf63c0d9",
   "metadata": {},
   "source": [
    "The output of the file above should be something like this:\n",
    "\n",
    "    [('Take 2017-02-20 07.26.44 PM', '24.45 MB'),\n",
    "     ('Take 2017-02-01 05.02.41 PM', '39.27 MB'),\n",
    "     ('Take 2017-03-07 03.11.44 PM_batch', '14.27 MB'),\n",
    "     ('Take 2017-03-07 02.29.11 PM_batch', '30.21 MB'),\n",
    "     ('Take 2017-03-07 03.11.44 PM', '13.43 MB'),\n",
    "     ('Take 2017-03-07 02.29.11 PM', '28.50 MB'),\n",
    "     ('Take 2017-02-17 01.48.32 PM', '64.16 MB'),\n",
    "     ('Take 2017-02-08 01.04.32 PM', '25.19 MB'),\n",
    "     ('Take 2017-02-08 01.47.29 PM', '15.13 MB'),\n",
    "     ('Take 2017-02-08 01.42.33 PM', '1.76 MB')]\n",
    "     \n",
    " Those files are very similar among themselves and as discussed previously most of them are located in the folders named \"Session {date}\" \n",
    " \n",
    " Let's open a random path to see what file to see what kind of information they have inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "503433d1-77d4-4093-8375-d5114b04931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_to_search = \".csv\"\n",
    "path_to_csv_list = [p for p in base_path.rglob(f\"*{format_to_search}\") if p.is_file()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "844098b3-2bd1-4631-9ccc-384d44c32ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/shared/catalystneuro/Buzsaki/TingleyD/DT9/20170522_900um_936um_170522_151132/Session 2017-05-22/Take 2017-05-22 03.37.41 PM_batch.csv')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "p = np.random.choice(path_to_csv_list)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529d088-cbe3-45cb-a982-5f18d5984e55",
   "metadata": {},
   "source": [
    "This should be a path object indicating the complete path to the file:\n",
    "\n",
    "`'/shared/catalystneuro/Buzsaki/TingleyD/DT9/20170522_900um_936um_170522_151132/Session 2017-05-22/Take 2017-05-22 03.37.41 PM_batch.csv'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98e4cba7-c2c6-4fd7-9ada-756d1e8c4ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.000000</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>-0.120431</td>\n",
       "      <td>0.879290</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.459574</td>\n",
       "      <td>328.160767</td>\n",
       "      <td>863.285339</td>\n",
       "      <td>622.358459</td>\n",
       "      <td>0.567362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.117984</td>\n",
       "      <td>0.881127</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.456455</td>\n",
       "      <td>328.562561</td>\n",
       "      <td>862.566406</td>\n",
       "      <td>622.785278</td>\n",
       "      <td>0.532845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.114739</td>\n",
       "      <td>0.882404</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.454669</td>\n",
       "      <td>328.857544</td>\n",
       "      <td>861.887329</td>\n",
       "      <td>623.203125</td>\n",
       "      <td>0.566924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.111382</td>\n",
       "      <td>0.883373</td>\n",
       "      <td>0.039152</td>\n",
       "      <td>0.453557</td>\n",
       "      <td>328.824890</td>\n",
       "      <td>861.194885</td>\n",
       "      <td>623.967590</td>\n",
       "      <td>0.546953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-0.109384</td>\n",
       "      <td>0.883821</td>\n",
       "      <td>0.042722</td>\n",
       "      <td>0.452846</td>\n",
       "      <td>328.706787</td>\n",
       "      <td>860.477905</td>\n",
       "      <td>624.920898</td>\n",
       "      <td>0.542314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.000000  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \\\n",
       "0  1  0.008333   -0.120431    0.879290    0.033715    0.459574  328.160767   \n",
       "1  2  0.016667   -0.117984    0.881127    0.036669    0.456455  328.562561   \n",
       "2  3  0.025000   -0.114739    0.882404    0.038400    0.454669  328.857544   \n",
       "3  4  0.033333   -0.111382    0.883373    0.039152    0.453557  328.824890   \n",
       "4  5  0.041667   -0.109384    0.883821    0.042722    0.452846  328.706787   \n",
       "\n",
       "   Unnamed: 7  Unnamed: 8  Unnamed: 9  \n",
       "0  863.285339  622.358459    0.567362  \n",
       "1  862.566406  622.785278    0.532845  \n",
       "2  861.887329  623.203125    0.566924  \n",
       "3  861.194885  623.967590    0.546953  \n",
       "4  860.477905  624.920898    0.542314  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(p)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e261f-4d3d-4c56-b3bb-7e19aa83bbee",
   "metadata": {},
   "source": [
    "The initial file does seem to have some columns. We can re-run the following cells to get an idea of how these files look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b0d20fa-0009-4797-95f8-a6e8aee376d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/catalystneuro/Buzsaki/TingleyD/DT7/20170327_864um_360um_170327_115803/Session 2017-03-27/Take 2017-03-27 03.45.19 PM_batch.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.000000</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.221911</td>\n",
       "      <td>-0.215985</td>\n",
       "      <td>-0.112192</td>\n",
       "      <td>-0.944203</td>\n",
       "      <td>187.646439</td>\n",
       "      <td>848.022705</td>\n",
       "      <td>41.524620</td>\n",
       "      <td>0.342710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.217375</td>\n",
       "      <td>-0.223007</td>\n",
       "      <td>-0.118962</td>\n",
       "      <td>-0.942796</td>\n",
       "      <td>188.166672</td>\n",
       "      <td>848.171204</td>\n",
       "      <td>41.057453</td>\n",
       "      <td>0.302789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.216126</td>\n",
       "      <td>-0.225629</td>\n",
       "      <td>-0.122170</td>\n",
       "      <td>-0.942049</td>\n",
       "      <td>188.228455</td>\n",
       "      <td>848.195984</td>\n",
       "      <td>41.224876</td>\n",
       "      <td>0.287108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.214703</td>\n",
       "      <td>-0.223274</td>\n",
       "      <td>-0.124896</td>\n",
       "      <td>-0.942578</td>\n",
       "      <td>187.707886</td>\n",
       "      <td>848.144836</td>\n",
       "      <td>41.479603</td>\n",
       "      <td>0.717094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.210819</td>\n",
       "      <td>-0.215694</td>\n",
       "      <td>-0.128672</td>\n",
       "      <td>-0.944709</td>\n",
       "      <td>187.569504</td>\n",
       "      <td>847.715881</td>\n",
       "      <td>41.604931</td>\n",
       "      <td>0.245150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.000000  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \\\n",
       "0  1  0.008333    0.221911   -0.215985   -0.112192   -0.944203  187.646439   \n",
       "1  2  0.016667    0.217375   -0.223007   -0.118962   -0.942796  188.166672   \n",
       "2  3  0.025000    0.216126   -0.225629   -0.122170   -0.942049  188.228455   \n",
       "3  4  0.033333    0.214703   -0.223274   -0.124896   -0.942578  187.707886   \n",
       "4  5  0.041667    0.210819   -0.215694   -0.128672   -0.944709  187.569504   \n",
       "\n",
       "   Unnamed: 7  Unnamed: 8  Unnamed: 9  \n",
       "0  848.022705   41.524620    0.342710  \n",
       "1  848.171204   41.057453    0.302789  \n",
       "2  848.195984   41.224876    0.287108  \n",
       "3  848.144836   41.479603    0.717094  \n",
       "4  847.715881   41.604931    0.245150  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.random.choice(path_to_csv_list)\n",
    "print(p)\n",
    "df_csv = pd.read_csv(p)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12bc9a-c3a0-4f64-858c-9cacabb79028",
   "metadata": {},
   "source": [
    "We find that some files seem to be list of positions. The following file is one of those examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4ea42d6-d52d-4272-a616-b8da5b314f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format Version</th>\n",
       "      <th>1.21</th>\n",
       "      <th>Take Name</th>\n",
       "      <th>Take 2017-02-17 01.48.32 PM</th>\n",
       "      <th>Capture Frame Rate</th>\n",
       "      <th>120.000000</th>\n",
       "      <th>Export Frame Rate</th>\n",
       "      <th>120.000000.1</th>\n",
       "      <th>Capture Start Time</th>\n",
       "      <th>2017-02-17 01.48.32 PM</th>\n",
       "      <th>Total Frames in Take</th>\n",
       "      <th>679616</th>\n",
       "      <th>Total Exported Frames</th>\n",
       "      <th>679616.1</th>\n",
       "      <th>Rotation Type</th>\n",
       "      <th>Quaternion</th>\n",
       "      <th>Length Units</th>\n",
       "      <th>Meters</th>\n",
       "      <th>Coordinate Space</th>\n",
       "      <th>Global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>Rigid Body</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>RigidBody 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>8392B20CF49E35732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position</td>\n",
       "      <td>Error Per Marker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frame</td>\n",
       "      <td>Time</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>Z</td>\n",
       "      <td>W</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Format Version  1.21          Take Name Take 2017-02-17 01.48.32 PM  \\\n",
       "0            NaN   NaN         Rigid Body                  Rigid Body   \n",
       "1            NaN   NaN        RigidBody 2                 RigidBody 2   \n",
       "2            NaN   NaN  8392B20CF49E35732           8392B20CF49E35732   \n",
       "3            NaN   NaN           Rotation                    Rotation   \n",
       "4          Frame  Time                  X                           Y   \n",
       "\n",
       "  Capture Frame Rate         120.000000  Export Frame Rate       120.000000.1  \\\n",
       "0         Rigid Body         Rigid Body         Rigid Body         Rigid Body   \n",
       "1        RigidBody 2        RigidBody 2        RigidBody 2        RigidBody 2   \n",
       "2  8392B20CF49E35732  8392B20CF49E35732  8392B20CF49E35732  8392B20CF49E35732   \n",
       "3           Rotation           Rotation           Position           Position   \n",
       "4                  Z                  W                  X                  Y   \n",
       "\n",
       "  Capture Start Time 2017-02-17 01.48.32 PM  Total Frames in Take  679616  \\\n",
       "0         Rigid Body             Rigid Body                   NaN     NaN   \n",
       "1        RigidBody 2            RigidBody 2                   NaN     NaN   \n",
       "2  8392B20CF49E35732      8392B20CF49E35732                   NaN     NaN   \n",
       "3           Position       Error Per Marker                   NaN     NaN   \n",
       "4                  Z                    NaN                   NaN     NaN   \n",
       "\n",
       "   Total Exported Frames  679616.1  Rotation Type  Quaternion  Length Units  \\\n",
       "0                    NaN       NaN            NaN         NaN           NaN   \n",
       "1                    NaN       NaN            NaN         NaN           NaN   \n",
       "2                    NaN       NaN            NaN         NaN           NaN   \n",
       "3                    NaN       NaN            NaN         NaN           NaN   \n",
       "4                    NaN       NaN            NaN         NaN           NaN   \n",
       "\n",
       "   Meters  Coordinate Space  Global  \n",
       "0     NaN               NaN     NaN  \n",
       "1     NaN               NaN     NaN  \n",
       "2     NaN               NaN     NaN  \n",
       "3     NaN               NaN     NaN  \n",
       "4     NaN               NaN     NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = Path(\"/home/jovyan/globus_data/TingleyD/DT8/20170217_216um_1944um_merge/Session 2017-02-17/Take 2017-02-17 01.48.32 PM.csv\")\n",
    "df_csv = pd.read_csv(file_path)\n",
    "df_csv.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buzsaki_lab_to_nwb",
   "language": "python",
   "name": "buzsaki_lab_to_nwb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
